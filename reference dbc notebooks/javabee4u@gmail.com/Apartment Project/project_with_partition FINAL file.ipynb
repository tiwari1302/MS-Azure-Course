{"cells":[{"cell_type":"code","source":["# http://optimus-ironmussa.readthedocs.io/en/latest/sections/transforming.html#dataframetransformer-replace-na-value-columns-none\n#d_frontend_t = finaldf.select( \"frontend_id\",\"network_id\",\"frontend_name\",\"parent_frontend\")\n#windowSpec = W.orderBy(\"frontend_id\",\"network_id\",\"frontend_name\",\"parent_frontend\")\n#d_frontend = d_frontend_t.distinct().withColumn(\"seq\", F.row_number().over(windowSpec))\n#d_frontend.write.mode(\"overwrite\").saveAsTable(\"d_frontend\")\n\n#windowSpec = W.orderBy(\"affiliate_id\",\"tracker_id\",\"referral_link\")\n\n#d_affl = finaldf.select(\"affiliate_id\",\"tracker_id\",\"referral_link\").distinct().withColumn(\"seq\", F.row_number().over(windowSpec))\n#d_affl.write.mode(\"overwrite\").saveAsTable(\"d_affl\")\n\nimport requests\nimport json\nimport optimus as op\nimport phonenumbers \nimport re\nimport datetime\n\nfrom pyspark.sql.types import StringType, IntegerType, TimestampType, DateType, DoubleType, StructType, StructField\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import HiveContext\nfrom pyspark.sql import SQLContext, Row\nfrom pyspark.sql.functions import unix_timestamp, from_unixtime\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.window import Window as W\nfrom functools import reduce  # For Python 3.x\nfrom pyspark.sql import DataFrame\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql.functions import rank, col\n\nimport time\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c131c432-249c-4e1a-94b0-b31ccbe5b318"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;IPython.core.display.HTML at 0x7fd5a9b14390&gt;\n&lt;IPython.core.display.HTML at 0x7fd5c3738b38&gt;\nDeleting previous folder if exists...\nCreation of checkpoint directory...\nDone.\n&lt;IPython.core.display.HTML at 0x7fd5c3738b38&gt;\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.HTML at 0x7fd5a9b14390&gt;\n&lt;IPython.core.display.HTML at 0x7fd5c3738b38&gt;\nDeleting previous folder if exists...\nCreation of checkpoint directory...\nDone.\n&lt;IPython.core.display.HTML at 0x7fd5c3738b38&gt;\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Create Spark Context\n\nsparkContext = SparkSession \\\n    .builder \\\n    .appName(\"Apartment POC\") \\\n    .getOrCreate()\n\n# Create Hive Context\nhivecontext=HiveContext(sparkContext)\n\n# configure Hive Context\nhivecontext.setConf('hive.support.concurrency','true');\nhivecontext.setConf('hive.enforce.bucketing','true');\nhivecontext.setConf('hive.exec.dynamic.partition.mode','nostrict');\nhivecontext.setConf('hive.compactor.initiator.on','true');\nhivecontext.setConf('hive.compactor.worker.threads','1');\n\nsqlContext = SQLContext(sparkContext)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"365776bd-6ecf-4adb-ae18-8f3e90337d3b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Schema for Landlord JSON\nlandlord_schema = StructType([\n            StructField(\"Landlord_id\", IntegerType(), False),\n            StructField(\"Password\", StringType(), True),\n            StructField(\"Landlord_name\", StringType(), False),\n            StructField(\"Address_line_1\", StringType(), False),\n            StructField(\"City\", StringType(), False),\n            StructField(\"Post_code\", StringType(), True),\n            StructField(\"Region\", StringType(), True)])\n\n\nlandlordSeq_schema = StructType([\n            StructField(\"landlord_seq\", IntegerType(), False),\n            StructField(\"Landlord_id\", IntegerType(), False),\n            StructField(\"Password\", StringType(), True),\n            StructField(\"Landlord_name\", StringType(), False),\n            StructField(\"Address_line_1\", StringType(), False),\n            StructField(\"City\", StringType(), False),\n            StructField(\"Post_code\", StringType(), True),\n            StructField(\"Region\", StringType(), True)])\n\n# Schema for building JSON\nbuilding_schema = StructType([\n            StructField(\"Landlord_id\", IntegerType(), False),\n            StructField(\"Building_name\", StringType(), True),\n            StructField(\"Address_line_1\", StringType(), False),\n            StructField(\"City\", StringType(), False),\n            StructField(\"Post_code\", StringType(), True),\n            StructField(\"Region\", StringType(), True)])\n\n# Schema for Apartment JSON\napartment_schema = StructType([\n            StructField(\"Apartment_number\", IntegerType(), True),\n            StructField(\"Type\", StringType(), True),\n            StructField(\"Rent_fee\", StringType(), True),\n            StructField(\"Building_name\", StringType(), True),\n            StructField(\"Appt_details\", StringType(), True)])\n\n# Schema for Contractor\ncontractor_schema = StructType([\n            StructField(\"Contract_id\", IntegerType(), False),\n            StructField(\"Name\", StringType(), True),\n            StructField(\"Address_line_1\", StringType(), False),\n            StructField(\"City\", StringType(), False),\n            StructField(\"Post_code\", StringType(), True),\n            StructField(\"Region\", StringType(), True)])\n\n# Schema for Tenant\ntenant_schema = StructType([\n            StructField(\"Tenant_id\", IntegerType(), False),\n            StructField(\"First_name\", StringType(), True),\n            StructField(\"Last_name\", StringType(), False),\n            StructField(\"Ssn\", StringType(), True),\n            StructField(\"Phone\", StringType(), True),\n            StructField(\"Email\", StringType(), True), \n            StructField(\"Mobile\", StringType(), True)])\n\n# Schema for Lease \nlease_schema = StructType([\n            StructField(\"Lease_id\", IntegerType(), False),\n            StructField(\"Start\", StringType(), True),\n            StructField(\"End\", StringType(), False),\n            StructField(\"Deposit\", StringType(), True),\n            StructField(\"Tenant_id\", IntegerType(), True),\n            StructField(\"Apartment_id\", IntegerType(), True)])\n\n# Schema  for Rent\nrent_schema = StructType([\n            StructField(\"Rent_id\", IntegerType(), False),\n            StructField(\"Rent_fee\", StringType(), True),\n            StructField(\"Late_fee\", StringType(), False),\n            StructField(\"Due_date\", TimestampType(), True),\n            StructField(\"Lease_id\", IntegerType(), True),\n            StructField(\"Pay_id\", IntegerType(), True)])\n\n# Schema for Payment\npayment_schema = StructType([\n            StructField(\"Payment_id\", IntegerType(), False),\n            StructField(\"Pay_date\", TimestampType(), True),\n            StructField(\"Pay_amount\", StringType(), False),\n            StructField(\"Method\", StringType(), True),\n            StructField(\"Rent_id\", IntegerType(), True)])\n\n# Schema for Apartment Maintenance\napt_maintenance_schema = StructType([\n            StructField(\"Maintenance_id\", IntegerType(), False),\n            StructField(\"Apartment_number\", IntegerType(), True),\n            StructField(\"Mdate\", StringType(), False),\n            StructField(\"Issue_reported\", StringType(), True),\n            StructField(\"Contractor_id\", IntegerType(), True), \n            StructField(\"Resolution\", StringType(), True), \n            StructField(\"Status\", StringType(), True),\n            StructField(\"Charges_incurred\", StringType(), True)])\n\n# Schema for Building Maintenance\nbuilding_maintenance_schema = StructType([\n            StructField(\"Maintenance_id\", IntegerType(), False),\n            StructField(\"Building_name\", StringType(), True),\n            StructField(\"Ndate\", StringType(), False),\n            StructField(\"Issue_reported\", StringType(), True),\n            StructField(\"Contractor_id\", IntegerType(), True), \n            StructField(\"Resolution\", StringType(), True), \n            StructField(\"Status\", StringType(), True)])\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e809d0e-cf8d-46a3-9e01-8404a5ccb007"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Function to get SparkDataFrame after reading JSON data from API\ndef getSparkDataFrame(url, schema):\n  appdf = requests.get(url)\n  objJSON = appdf.json()\n  a=[json.dumps(objJSON)]\n  jsonRDD = sc.parallelize(a)\n  df = spark.read.schema(schema).json(jsonRDD)\n  return df\n\n# convert string value to Float value\ndef string_to_float(x):\n  return float(x[1:])\n\n# Get DataFrame without new Line characters\n# Especially for Apartment, ApartmentMaintenance\n\ndef getSparkDataFrameWithoutLFChar(url, schema):\n  appdf = requests.get(url)\n  str=''\n  for line in appdf.iter_lines():\n    str = line.decode(encoding='utf-8', errors='strict')\n    # escaping \\n works for python3, if it's python 2 no need to escape\n    str = str.replace('\\\\n', '')\n  json_str=json.loads(str)\n  df = spark.createDataFrame(json_str, schema)\n  return df\n\nudfstring_to_float = udf(string_to_float, StringType())\n\ndef fixTenantRow(c):\n    # get the Mobile field\n    number = c.Mobile\n\n    # initialize variables \n    is_valid_number = \"N\"\n    clean_number = None\n    number_type = None\n    valid_mail = None\n\n    p = None\n\n    if number is not None:\n        # Clean the Mobile Number first\n        try:\n            p = phonenumbers.parse(number, None)\n\n            if phonenumbers.is_valid_number(p):\n                is_valid_number = \"Y\"\n            elif phonenumbers.truncate_too_long_number(p):\n                is_valid_number = \"Y\"\n            else:\n                is_valid_number = \"N\"\n\n            clean_number = \"%s%s\" % (p.country_code, p.national_number)\n            \n        except:\n            p = None\n\n    # clean up PhoneNumber\n    phone_no = c.Phone\n    if phone_no is not None:\n      phone_no = phone_no.replace(' ', '')\n      if (len(phone_no) != 10):\n        phone_no = None\n    \n    # validate Email \n    if re.match(r\"^[A-Za-z0-9\\.\\+_-]+@[A-Za-z0-9\\._-]+\\.[a-zA-Z]*$\", c.Email):\n      valid_mail = c.Email\n    \n    return Row( \n\t\tTenant_id = c.Tenant_id,\n\t\tFirst_name = c.First_name,\n\t\tLast_name = c.Last_name,\n\t\tSsn = c.Ssn,\n\t\tPhone = phone_no,\n\t\tEmail = valid_mail,\n        Mobile=clean_number \n    )\n\n  \n# Create function to check each row if it exists in db\ndef checkIsRowExists(c, table_df):\n  \n  existing_row = table_df.filter(table_df.Landlord_id.isin(c.Landlord_id)) \n  if (existing_row.count() > 0):\n    return Row(\n        landlord_seq = existing_row.landlord_seq,\n        Landlord_id = c.Landlord_id,\n        Password = c.Password,\n        Landlord_name = c.Landlord_name,\n        Address_line_1 = c.Landlord_name,\n        City = c.City,\n        Post_code = c.Post_code,\n        Region = c.Region\n    )\n  else:\n    return Row(\n      landlord_seq = null,\n      Landlord_id = null,\n      Password = c.Password,\n      Landlord_name = c.Landlord_name,\n      Address_line_1 = c.Landlord_name,\n      City = c.City,\n      Post_code = c.Post_code,\n      Region = c.Region\n    )\n\n\n# function validating Post Code  \ndef validatePostCode(postCode):\n  if (re.match(r\"^[0-9]{5}(-[0-9]{4})?$\", postCode)):\n    return postCode\n  else:\n    return None\n  \ndef unionAll(*dfs):\n  return reduce(DataFrame.unionAll, dfs)\n\n\n# UDF for validatePostCode function  \nudfValidatePostCode = udf(validatePostCode, StringType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5d51f8dd-0ebc-4551-92c9-090e010b29fb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[" "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b81f4cb-7722-4882-9dce-1116a1731fe7"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = getSparkDataFrame(\"https://my.api.mockaroo.com/landlord.json?key=6af9c3e0\", landlord_schema)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28d550a5-5ddf-4a57-b6a2-4cc03eb42fd6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">JSONDecodeError</span>                           Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-689586480842093&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>df <span class=\"ansiyellow\">=</span> getSparkDataFrame<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;https://my.api.mockaroo.com/landlord.json?key=6af9c3e0&quot;</span><span class=\"ansiyellow\">,</span> landlord_schema<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;command-3517676877745081&gt;</span> in <span class=\"ansicyan\">getSparkDataFrame</span><span class=\"ansiblue\">(url, schema)</span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansigreen\">def</span> getSparkDataFrame<span class=\"ansiyellow\">(</span>url<span class=\"ansiyellow\">,</span> schema<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span>   appdf <span class=\"ansiyellow\">=</span> requests<span class=\"ansiyellow\">.</span>get<span class=\"ansiyellow\">(</span>url<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 4</span><span class=\"ansiyellow\">   </span>objJSON <span class=\"ansiyellow\">=</span> appdf<span class=\"ansiyellow\">.</span>json<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span>   a<span class=\"ansiyellow\">=</span><span class=\"ansiyellow\">[</span>json<span class=\"ansiyellow\">.</span>dumps<span class=\"ansiyellow\">(</span>objJSON<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      6</span>   jsonRDD <span class=\"ansiyellow\">=</span> sc<span class=\"ansiyellow\">.</span>parallelize<span class=\"ansiyellow\">(</span>a<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/requests/models.py</span> in <span class=\"ansicyan\">json</span><span class=\"ansiblue\">(self, **kwargs)</span>\n<span class=\"ansigreen\">    824</span>                     <span class=\"ansired\"># used.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    825</span>                     <span class=\"ansigreen\">pass</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 826</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> complexjson<span class=\"ansiyellow\">.</span>loads<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>text<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kwargs<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    827</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    828</span>     <span class=\"ansiyellow\">@</span>property<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/simplejson/__init__.py</span> in <span class=\"ansicyan\">loads</span><span class=\"ansiblue\">(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, **kw)</span>\n<span class=\"ansigreen\">    514</span>             parse_constant <span class=\"ansigreen\">is</span> <span class=\"ansigreen\">None</span> <span class=\"ansigreen\">and</span> object_pairs_hook <span class=\"ansigreen\">is</span> <span class=\"ansigreen\">None</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    515</span>             and not use_decimal and not kw):\n<span class=\"ansigreen\">--&gt; 516</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> _default_decoder<span class=\"ansiyellow\">.</span>decode<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    517</span>     <span class=\"ansigreen\">if</span> cls <span class=\"ansigreen\">is</span> <span class=\"ansigreen\">None</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    518</span>         cls <span class=\"ansiyellow\">=</span> JSONDecoder<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/simplejson/decoder.py</span> in <span class=\"ansicyan\">decode</span><span class=\"ansiblue\">(self, s, _w, _PY3)</span>\n<span class=\"ansigreen\">    368</span>         <span class=\"ansigreen\">if</span> _PY3 <span class=\"ansigreen\">and</span> isinstance<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">,</span> binary_type<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    369</span>             s <span class=\"ansiyellow\">=</span> s<span class=\"ansiyellow\">.</span>decode<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>encoding<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 370</span><span class=\"ansiyellow\">         </span>obj<span class=\"ansiyellow\">,</span> end <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>raw_decode<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    371</span>         end <span class=\"ansiyellow\">=</span> _w<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">,</span> end<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>end<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    372</span>         <span class=\"ansigreen\">if</span> end <span class=\"ansiyellow\">!=</span> len<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/simplejson/decoder.py</span> in <span class=\"ansicyan\">raw_decode</span><span class=\"ansiblue\">(self, s, idx, _w, _PY3)</span>\n<span class=\"ansigreen\">    398</span>             <span class=\"ansigreen\">elif</span> ord0 <span class=\"ansiyellow\">==</span> <span class=\"ansicyan\">0xef</span> <span class=\"ansigreen\">and</span> s<span class=\"ansiyellow\">[</span>idx<span class=\"ansiyellow\">:</span>idx <span class=\"ansiyellow\">+</span> <span class=\"ansicyan\">3</span><span class=\"ansiyellow\">]</span> <span class=\"ansiyellow\">==</span> <span class=\"ansiblue\">&apos;\\xef\\xbb\\xbf&apos;</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    399</span>                 idx <span class=\"ansiyellow\">+=</span> <span class=\"ansicyan\">3</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 400</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>scan_once<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">,</span> idx<span class=\"ansiyellow\">=</span>_w<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">,</span> idx<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>end<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">JSONDecodeError</span>: Expecting value: line 1 column 1 (char 0)</div>","errorSummary":"<span class=\"ansired\">JSONDecodeError</span>: Expecting value: line 1 column 1 (char 0)","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">JSONDecodeError</span>                           Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-689586480842093&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>df <span class=\"ansiyellow\">=</span> getSparkDataFrame<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;https://my.api.mockaroo.com/landlord.json?key=6af9c3e0&quot;</span><span class=\"ansiyellow\">,</span> landlord_schema<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;command-3517676877745081&gt;</span> in <span class=\"ansicyan\">getSparkDataFrame</span><span class=\"ansiblue\">(url, schema)</span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansigreen\">def</span> getSparkDataFrame<span class=\"ansiyellow\">(</span>url<span class=\"ansiyellow\">,</span> schema<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span>   appdf <span class=\"ansiyellow\">=</span> requests<span class=\"ansiyellow\">.</span>get<span class=\"ansiyellow\">(</span>url<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 4</span><span class=\"ansiyellow\">   </span>objJSON <span class=\"ansiyellow\">=</span> appdf<span class=\"ansiyellow\">.</span>json<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span>   a<span class=\"ansiyellow\">=</span><span class=\"ansiyellow\">[</span>json<span class=\"ansiyellow\">.</span>dumps<span class=\"ansiyellow\">(</span>objJSON<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      6</span>   jsonRDD <span class=\"ansiyellow\">=</span> sc<span class=\"ansiyellow\">.</span>parallelize<span class=\"ansiyellow\">(</span>a<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/requests/models.py</span> in <span class=\"ansicyan\">json</span><span class=\"ansiblue\">(self, **kwargs)</span>\n<span class=\"ansigreen\">    824</span>                     <span class=\"ansired\"># used.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    825</span>                     <span class=\"ansigreen\">pass</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 826</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> complexjson<span class=\"ansiyellow\">.</span>loads<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>text<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kwargs<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    827</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    828</span>     <span class=\"ansiyellow\">@</span>property<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/simplejson/__init__.py</span> in <span class=\"ansicyan\">loads</span><span class=\"ansiblue\">(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, **kw)</span>\n<span class=\"ansigreen\">    514</span>             parse_constant <span class=\"ansigreen\">is</span> <span class=\"ansigreen\">None</span> <span class=\"ansigreen\">and</span> object_pairs_hook <span class=\"ansigreen\">is</span> <span class=\"ansigreen\">None</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    515</span>             and not use_decimal and not kw):\n<span class=\"ansigreen\">--&gt; 516</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> _default_decoder<span class=\"ansiyellow\">.</span>decode<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    517</span>     <span class=\"ansigreen\">if</span> cls <span class=\"ansigreen\">is</span> <span class=\"ansigreen\">None</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    518</span>         cls <span class=\"ansiyellow\">=</span> JSONDecoder<span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/simplejson/decoder.py</span> in <span class=\"ansicyan\">decode</span><span class=\"ansiblue\">(self, s, _w, _PY3)</span>\n<span class=\"ansigreen\">    368</span>         <span class=\"ansigreen\">if</span> _PY3 <span class=\"ansigreen\">and</span> isinstance<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">,</span> binary_type<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    369</span>             s <span class=\"ansiyellow\">=</span> s<span class=\"ansiyellow\">.</span>decode<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>encoding<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 370</span><span class=\"ansiyellow\">         </span>obj<span class=\"ansiyellow\">,</span> end <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>raw_decode<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    371</span>         end <span class=\"ansiyellow\">=</span> _w<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">,</span> end<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>end<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    372</span>         <span class=\"ansigreen\">if</span> end <span class=\"ansiyellow\">!=</span> len<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/lib/python3.5/site-packages/simplejson/decoder.py</span> in <span class=\"ansicyan\">raw_decode</span><span class=\"ansiblue\">(self, s, idx, _w, _PY3)</span>\n<span class=\"ansigreen\">    398</span>             <span class=\"ansigreen\">elif</span> ord0 <span class=\"ansiyellow\">==</span> <span class=\"ansicyan\">0xef</span> <span class=\"ansigreen\">and</span> s<span class=\"ansiyellow\">[</span>idx<span class=\"ansiyellow\">:</span>idx <span class=\"ansiyellow\">+</span> <span class=\"ansicyan\">3</span><span class=\"ansiyellow\">]</span> <span class=\"ansiyellow\">==</span> <span class=\"ansiblue\">&apos;\\xef\\xbb\\xbf&apos;</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    399</span>                 idx <span class=\"ansiyellow\">+=</span> <span class=\"ansicyan\">3</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 400</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>scan_once<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">,</span> idx<span class=\"ansiyellow\">=</span>_w<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">,</span> idx<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>end<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">JSONDecodeError</span>: Expecting value: line 1 column 1 (char 0)</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Get Landlord JSON from API\ndf = getSparkDataFrame(\"https://my.api.mockaroo.com/landlord.json?key=6af9c3e0\", landlord_schema)\ndf.printSchema()\ndf.show(5)\n\nlandlord_df = df.withColumn(\"PostCode\", udfValidatePostCode(\"Post_code\") )\nlandlord_df = landlord_df.select(landlord_df.Landlord_id, landlord_df.Password, landlord_df.Landlord_name, landlord_df.Address_line_1,  landlord_df.City, landlord_df.PostCode, landlord_df.Region)\nlandlord_df = landlord_df.withColumnRenamed(\"PostCode\", \"Post_code\")\n\n# Instantiation of DataTransformer class:\ntransformer = op.DataFrameTransformer(landlord_df)\n# Replace NA with 0's\ntransformer.replace_na(0.0, columns=\"*\")\n# Clear accents: clear_accents only from name column and not everywhere \ntransformer.clear_accents(columns='*')\n# Remove special characters:  From all Columns \ntransformer.remove_special_chars(columns=['Landlord_name', 'Address_line_1', 'City', 'Region'])\n# Create Temp table \n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"09ab2d8a-d91a-47af-b64d-143f7cdd2bfc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Landlord_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Password","nullable":true,"type":"string"},{"metadata":{},"name":"Landlord_name","nullable":false,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":false,"type":"string"},{"metadata":{},"name":"City","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"landlord_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Landlord_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Password","nullable":true,"type":"string"},{"metadata":{},"name":"Landlord_name","nullable":false,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":false,"type":"string"},{"metadata":{},"name":"City","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- Landlord_id: integer (nullable = false)\n |-- Password: string (nullable = true)\n |-- Landlord_name: string (nullable = false)\n |-- Address_line_1: string (nullable = false)\n |-- City: string (nullable = false)\n |-- Post_code: string (nullable = true)\n |-- Region: string (nullable = true)\n\n+-----------+------------+-------------------+--------------------+------------+---------+--------+\n|Landlord_id|    Password|      Landlord_name|      Address_line_1|        City|Post_code|  Region|\n+-----------+------------+-------------------+--------------------+------------+---------+--------+\n|        424| vzwPbJ3vukg|  Patrice Cauderlie|   764 Ramsey Center|    Honolulu|    96845|  Hawaii|\n|        649| Upq0MGk6fBT|   Tildie Freeborne|    335 6th Crossing|     Atlanta|    31136| Georgia|\n|        419|   OODLlLVHa|   Muffin Schiersch|6269 Menomonie St...|White Plains|    10606|New York|\n|        314| ii9fn7hLtbC|Milissent Kinghorne|      0 Gina Terrace|     El Paso|    88519|   Texas|\n|        574|TLf9Kjqj82Qj|      Marris Oxtoby| 28830 Morning Place|      Arvada|    80005|Colorado|\n+-----------+------------+-------------------+--------------------+------------+---------+--------+\nonly showing top 5 rows\n\n<span class=\"ansired\">Out[</span><span class=\"ansired\">68</span><span class=\"ansired\">]: </span>&lt;optimus.df_transformer.DataFrameTransformer at 0x7f666e0e1668&gt;\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Landlord_id: integer (nullable = false)\n-- Password: string (nullable = true)\n-- Landlord_name: string (nullable = false)\n-- Address_line_1: string (nullable = false)\n-- City: string (nullable = false)\n-- Post_code: string (nullable = true)\n-- Region: string (nullable = true)\n\n+-----------+------------+-------------------+--------------------+------------+---------+--------+\nLandlord_id|    Password|      Landlord_name|      Address_line_1|        City|Post_code|  Region|\n+-----------+------------+-------------------+--------------------+------------+---------+--------+\n        424| vzwPbJ3vukg|  Patrice Cauderlie|   764 Ramsey Center|    Honolulu|    96845|  Hawaii|\n        649| Upq0MGk6fBT|   Tildie Freeborne|    335 6th Crossing|     Atlanta|    31136| Georgia|\n        419|   OODLlLVHa|   Muffin Schiersch|6269 Menomonie St...|White Plains|    10606|New York|\n        314| ii9fn7hLtbC|Milissent Kinghorne|      0 Gina Terrace|     El Paso|    88519|   Texas|\n        574|TLf9Kjqj82Qj|      Marris Oxtoby| 28830 Morning Place|      Arvada|    80005|Colorado|\n+-----------+------------+-------------------+--------------------+------------+---------+--------+\nonly showing top 5 rows\n\n<span class=\"ansired\">Out[</span><span class=\"ansired\">68</span><span class=\"ansired\">]: </span>&lt;optimus.df_transformer.DataFrameTransformer at 0x7f666e0e1668&gt;\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# This is for date\ndateStr = datetime.date.today().strftime(\"%m-%d-%Y\")\nprint(dateStr)\n# this is for timestamp \ndateTimeStr = datetime.datetime.today().strftime(\"%m-%d-%Y %H:%M:%S\")\n\nselectSql =\" select Landlord_id, Password, Landlord_name, Address_line_1, City, Post_code, Region from landlord_data where Load_date like '\" + dateStr + \"%'\"\n\nselectSqlWithSeq = \" select  landlord_seq, Landlord_id, Password, Landlord_name, Address_line_1, City, Post_code, Region from landlord_data where Load_date like '\" + dateStr + \"%'\"\n\n# Get existing record from Landlord table\nlandlord_table_df = hivecontext.sql(selectSql)\n\nlandlord_table_full_df = hivecontext.sql(selectSqlWithSeq)\nprint(landlord_table_df.count())\nexisting_rows = landlord_table_df.count()\n# get new rows from landlord_df by comparing it with Table data\nnew_df =landlord_df.subtract( landlord_table_df)  \nprint(new_df.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cfc172db-b580-4a4b-a90c-0eaca6791c16"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"landlord_table_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Landlord_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Password","nullable":true,"type":"string"},{"metadata":{},"name":"Landlord_name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":true,"type":"string"},{"metadata":{},"name":"City","nullable":true,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"landlord_table_full_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"landlord_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Landlord_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Password","nullable":true,"type":"string"},{"metadata":{},"name":"Landlord_name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":true,"type":"string"},{"metadata":{},"name":"City","nullable":true,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"new_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Landlord_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Password","nullable":true,"type":"string"},{"metadata":{},"name":"Landlord_name","nullable":false,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":false,"type":"string"},{"metadata":{},"name":"City","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">03-22-2018\n151\n50\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">03-22-2018\n151\n50\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["landlord_existing_rows = None\nif (existing_rows > 0):\n  new_rows_df = new_df.withColumnRenamed(\"Password\", \"Password_1\").withColumnRenamed(\"Landlord_name\", \"Landlord_name_1\").withColumnRenamed(\"Address_line_1\", \"Address_line_1_1\").withColumnRenamed(\"City\", \"City_1\") .withColumnRenamed(\"Post_code\", \"Post_code_1\") .withColumnRenamed(\"Region\", \"Region_1\")    \n\n  final_join_df = landlord_table_df.join(new_rows_df, landlord_table_df.Landlord_id == landlord_df.Landlord_id,  'outer') \\\n                  .select(landlord_table_df.Landlord_id, \\\n                          F.when(new_rows_df.Password_1 != landlord_table_df.Password, \n                                 new_rows_df.Password_1). otherwise(landlord_table_df.Password).alias(\"Password\") ,\n                          F.when(new_rows_df.Landlord_name_1 != landlord_table_df.Landlord_name, \n                                 new_rows_df.Landlord_name_1).otherwise(landlord_table_df.Landlord_name).alias(\"Landlord_name\"), \n                          F.when(new_rows_df.Address_line_1_1 != landlord_table_df.Address_line_1, \n                                 new_rows_df.Address_line_1_1 ).otherwise(landlord_table_df.Address_line_1).alias(\"Address_line_1\"), \n                          F.when(new_rows_df.City_1 != landlord_table_df.City, \n                                 new_rows_df.City_1 ).otherwise(landlord_table_df.City).alias(\"City\"), \n                          F.when(new_rows_df.Post_code_1 != landlord_table_df.Post_code, \n                                 new_rows_df.Post_code_1 ).otherwise(landlord_table_df.Post_code).alias(\"Post_code\"), \n                          F.when(new_rows_df.Region_1 != landlord_table_df.Region, \n                                 new_rows_df.Region_1 ).otherwise(landlord_table_df.Region).alias(\"Region\")) \\\n                .filter(landlord_table_df.Landlord_id.isNotNull()) \n  \n  \n  # check If Id's already available in the table\n\n  \n  landlord_existing_rows_df = (landlord_table_full_df.select('Landlord_id', 'Landlord_name')).intersect(new_df.select('Landlord_id', 'Landlord_name'))\n  print(landlord_existing_rows_df.count())\n  if (landlord_existing_rows_df.count() > 0):\n    # it will have only landlord_id and landlordname..\n    # get other columns also\n    landlord_existing_rows = landloard_existsing_rows_df.join(new_df, \"Landlord_id\")\n    # join to get Landlord_seq column from landlord table\n    landloard_existsing_rows = landloard_existsing_rows.join(landlord_table_full_df, \"Landlord_id\")\n    # re-arrange the columns now\n    landloard_existsing_rows = landloard_existsing_rows.select(\"landlord_seq\", \\\n                                                               \"Landlord_id\", \\\n                                                               \"Password\", \\\n                                                               \"Landlord_name\", \\\n                                                               \"Address_line_1\", \\\n                                                               \"City\", \\\n                                                               \"Post_code\", \\\n                                                               \"Region\" )\nelse:\n  final_join_df = new_df\n\n# Add landlord_seq column \nwindowSpec = W.orderBy(\"Landlord_id\",\"Landlord_name\",\"City\",\"Region\")\nfinal_join_df = final_join_df.distinct().withColumn(\"landlord_seq\", F.row_number().over(windowSpec))  \n# make sure column are in order\nfinal_join_df = final_join_df.select(\"landlord_seq\", \"Landlord_id\", \"Password\", \"Landlord_name\", \"Address_line_1\", \"City\", \"Post_code\", \"Region\" )\n\n# Join the existing rows\nif landlord_existing_rows is not None:\n  landlord_existing_rows.show()\n  final_join_df = unionAll(landlord_existing_rows, final_join_df) \n\n\ntimestamp = datetime.datetime.fromtimestamp(time.time())\ndateTimeStr = datetime.datetime.today().strftime(\"%m-%d-%Y %H:%M:%S\")\n\nfinal_join_df = final_join_df.withColumn(\"EventTimestamp\", lit(timestamp))\nfinal_join_df = final_join_df.withColumn(\"Load_date\", lit(dateTimeStr))\n\n\nfinal_join_df = final_join_df.select(\"landlord_seq\", \"Landlord_id\", \"Password\", \"Landlord_name\", \"Address_line_1\", \"City\", \"Post_code\", \"Region\", \"EventTimestamp\", \"Load_date\" )\nfinal_join_df.printSchema() \nfinal_join_df.write.insertInto(\"landlord_data\")\n\nlandlord_table_count = hivecontext.sql(\"select * from landlord_data\")\nprint(landlord_table_count.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e35ebd5c-9f5a-4ca4-a7bb-23a7e3acef9b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"new_rows_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Landlord_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Password_1","nullable":true,"type":"string"},{"metadata":{},"name":"Landlord_name_1","nullable":false,"type":"string"},{"metadata":{},"name":"Address_line_1_1","nullable":false,"type":"string"},{"metadata":{},"name":"City_1","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code_1","nullable":true,"type":"string"},{"metadata":{},"name":"Region_1","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"landlord_existing_rows_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Landlord_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Landlord_name","nullable":false,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"final_join_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"landlord_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Landlord_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Password","nullable":true,"type":"string"},{"metadata":{},"name":"Landlord_name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":true,"type":"string"},{"metadata":{},"name":"City","nullable":true,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"},{"metadata":{},"name":"EventTimestamp","nullable":false,"type":"timestamp"},{"metadata":{},"name":"Load_date","nullable":false,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"landlord_table_count","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"landlord_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Landlord_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Password","nullable":true,"type":"string"},{"metadata":{},"name":"Landlord_name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":true,"type":"string"},{"metadata":{},"name":"City","nullable":true,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"},{"metadata":{},"name":"EventTimestamp","nullable":true,"type":"timestamp"},{"metadata":{},"name":"Load_date","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">0\nroot\n |-- landlord_seq: integer (nullable = true)\n |-- Landlord_id: integer (nullable = true)\n |-- Password: string (nullable = true)\n |-- Landlord_name: string (nullable = true)\n |-- Address_line_1: string (nullable = true)\n |-- City: string (nullable = true)\n |-- Post_code: string (nullable = true)\n |-- Region: string (nullable = true)\n |-- EventTimestamp: timestamp (nullable = false)\n |-- Load_date: string (nullable = false)\n\n409\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0\nroot\n-- landlord_seq: integer (nullable = true)\n-- Landlord_id: integer (nullable = true)\n-- Password: string (nullable = true)\n-- Landlord_name: string (nullable = true)\n-- Address_line_1: string (nullable = true)\n-- City: string (nullable = true)\n-- Post_code: string (nullable = true)\n-- Region: string (nullable = true)\n-- EventTimestamp: timestamp (nullable = false)\n-- Load_date: string (nullable = false)\n\n409\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Get Building JSON from API\ndf = getSparkDataFrame(\"https://my.api.mockaroo.com/building.json?key=6af9c3e0\", building_schema)\ndf.printSchema()\n\nbuilding_df = df.withColumn(\"PostCode\", udfValidatePostCode(\"Post_code\") )\nbuilding_df = building_df.select(building_df.Landlord_id, building_df.Building_name, building_df.Address_line_1,  building_df.City, building_df.PostCode, building_df.Region)\nbuilding_df = building_df.withColumnRenamed(\"PostCode\", \"Post_code\") \n\n# Instantiation of DataTransformer class:\ntransformer = op.DataFrameTransformer(building_df)\n# Replace NA with 0's\ntransformer.replace_na(0.0, columns=\"*\")\n# Clear accents: clear_accents only from name column and not everywhere \ntransformer.clear_accents(columns='*')\n# Remove special characters:  From all Columns \ntransformer.remove_special_chars(columns=['Building_name', 'Address_line_1', 'City', 'Region'])\n# Create Temp table \nbuilding_df.registerTempTable('building_temp')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb0a28e8-0bb5-4b34-bfcb-8f5044fdc3c5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Landlord_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":false,"type":"string"},{"metadata":{},"name":"City","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"building_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Landlord_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":false,"type":"string"},{"metadata":{},"name":"City","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- Landlord_id: integer (nullable = false)\n |-- Building_name: string (nullable = true)\n |-- Address_line_1: string (nullable = false)\n |-- City: string (nullable = false)\n |-- Post_code: string (nullable = true)\n |-- Region: string (nullable = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Landlord_id: integer (nullable = false)\n-- Building_name: string (nullable = true)\n-- Address_line_1: string (nullable = false)\n-- City: string (nullable = false)\n-- Post_code: string (nullable = true)\n-- Region: string (nullable = true)\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# 1. get all the landlord records\nlandlord_df = hivecontext.sql (\"select landlord_seq, Landlord_id, load_date from landlord_data order by load_date desc\")\n# 2. Now join the building DF with landlord df to get the sequence\nbuilding_df_with_seq = building_df.join(landlord_df, \"Landlord_id\") "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"085149ef-a1e1-48f5-a69f-08ba8a487c55"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"landlord_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"landlord_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Landlord_id","nullable":true,"type":"integer"},{"metadata":{},"name":"load_date","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"building_df_with_seq","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Landlord_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":false,"type":"string"},{"metadata":{},"name":"City","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"},{"metadata":{},"name":"landlord_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"load_date","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["import datetime\n# This is for date\ndateStr = datetime.date.today().strftime(\"%m-%d-%Y\")\nprint(dateStr)\n# this is for timestamp \ndateTimeStr = datetime.datetime.today().strftime(\"%m-%d-%Y %H:%M:%S\")\n\n# get the Landlord_seq for landlord_id data\n\n# 1. get all the landlord records\nlandlord_df = hivecontext.sql (\"select landlord_seq, Landlord_id, load_date from landlord_data order by load_date desc\")\n# 2. Now join the building DF with landlord df to get the sequence\nbuilding_df_with_seq = building_df.join(landlord_df, \"Landlord_id\") \n\nwindowSpec = W.partitionBy(\"landlord_seq\",\"Landlord_id\",\"City\", \"Post_code\" ).orderBy(col(\"load_date\").desc())\n\nbuilding_df_with_seq = building_df_with_seq.select('*', rank().over(windowSpec).alias('rank')) \\\n  .filter(col('rank') <= 1) \nbuilding_df_with_seq = building_df_with_seq.drop(\"rank\")\n \n# exclude all the rows with seq from Building_df\nbuilding_df = building_df.join(building_df_with_seq, \"Landlord_id\", \"leftanti\")\n \n# now it's time to insert building data into table\n\n# Add landlord_seq column \nbuilding_df = building_df.withColumn(\"landlord_seq\", lit(-1))  \n \n# Join the existing rows\nif building_df_with_seq is not None:\n  building_df_with_seq = building_df_with_seq.select(\"landlord_seq\", \"Landlord_id\", \"Building_name\",  \"Address_line_1\", \"City\", \"Post_code\", \"Region\" )\n  building_df  = building_df.select(\"landlord_seq\", \"Landlord_id\", \"Building_name\",  \"Address_line_1\", \"City\", \"Post_code\", \"Region\" )\n\n  final_join_df = unionAll(building_df, building_df_with_seq) \nelse:\n  final_join_df = building_df\n\n  \n# Add building_seq column \nwindowSpec = W.orderBy(\"Landlord_id\",\"Building_name\",\"City\",\"Region\")\nfinal_join_df = final_join_df.distinct().withColumn(\"building_seq\", F.row_number().over(windowSpec))  \n \ntimestamp = datetime.datetime.fromtimestamp(time.time())\ndateTimeStr = datetime.datetime.today().strftime(\"%m-%d-%Y %H:%M:%S\")\n\nfinal_join_df = final_join_df.withColumn(\"EventTimestamp\", lit(timestamp))\nfinal_join_df = final_join_df.withColumn(\"Load_date\", lit(dateTimeStr))\n\n\nfinal_join_df = final_join_df.select(\"building_seq\", \"landlord_seq\", \"Landlord_id\", \"Building_name\",  \"Address_line_1\", \"City\", \"Post_code\", \"Region\" ,\"EventTimestamp\", \"Load_date\" )\nfinal_join_df.printSchema() \nfinal_join_df.write.insertInto(\"building_data\")\n\nbuilding_table_count = hivecontext.sql(\"select * from building_data\")\nprint(building_table_count.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da144a4d-d265-4e70-8c8c-a0c3d824ed84"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"landlord_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"landlord_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Landlord_id","nullable":true,"type":"integer"},{"metadata":{},"name":"load_date","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"building_df_with_seq","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"landlord_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Landlord_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":false,"type":"string"},{"metadata":{},"name":"City","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"building_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"landlord_seq","nullable":false,"type":"integer"},{"metadata":{},"name":"Landlord_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":false,"type":"string"},{"metadata":{},"name":"City","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"final_join_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"building_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"landlord_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Landlord_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":false,"type":"string"},{"metadata":{},"name":"City","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"},{"metadata":{},"name":"EventTimestamp","nullable":false,"type":"timestamp"},{"metadata":{},"name":"Load_date","nullable":false,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"building_table_count","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"building_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"landlord_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Landlord_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":true,"type":"string"},{"metadata":{},"name":"City","nullable":true,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"},{"metadata":{},"name":"EventTimestamp","nullable":true,"type":"timestamp"},{"metadata":{},"name":"Load_date","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">03-22-2018\nroot\n |-- building_seq: integer (nullable = true)\n |-- landlord_seq: integer (nullable = true)\n |-- Landlord_id: integer (nullable = false)\n |-- Building_name: string (nullable = true)\n |-- Address_line_1: string (nullable = false)\n |-- City: string (nullable = false)\n |-- Post_code: string (nullable = true)\n |-- Region: string (nullable = true)\n |-- EventTimestamp: timestamp (nullable = false)\n |-- Load_date: string (nullable = false)\n\n250\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">03-22-2018\nroot\n-- building_seq: integer (nullable = true)\n-- landlord_seq: integer (nullable = true)\n-- Landlord_id: integer (nullable = false)\n-- Building_name: string (nullable = true)\n-- Address_line_1: string (nullable = false)\n-- City: string (nullable = false)\n-- Post_code: string (nullable = true)\n-- Region: string (nullable = true)\n-- EventTimestamp: timestamp (nullable = false)\n-- Load_date: string (nullable = false)\n\n250\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Get Apartment JSON from API\ndf = getSparkDataFrameWithoutLFChar(\"https://my.api.mockaroo.com/apartment.json?key=6af9c3e0\", apartment_schema)\n \napartment_df = df.withColumn(\"RentFee\", udfstring_to_float(\"Rent_fee\") )\napartment_df = apartment_df.select(apartment_df.Apartment_number, apartment_df.Type, apartment_df.RentFee.cast(\"float\"), apartment_df.Building_name, apartment_df.Appt_details)\napartment_df = apartment_df.withColumnRenamed(\"RentFee\", \"Rent_fee\") \n\napartment_df.printSchema()\napartment_df.show(5)\n# Instantiation of DataTransformer class:\ntransformer = op.DataFrameTransformer(apartment_df)\n# Replace NA with 0's\ntransformer.replace_na(0.0, columns=\"*\")\n# Clear accents: clear_accents only from name column and not everywhere \ntransformer.clear_accents(columns='*')\n# Remove special characters:  From all Columns \ntransformer.remove_special_chars(columns=['Building_name', 'Appt_details'])\n# Create Temp table \napartment_df.registerTempTable('apartment_temp')\napartment_df.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff5e1f3e-cb1c-4306-a234-755c40786d8e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Apartment_number","nullable":true,"type":"integer"},{"metadata":{},"name":"Type","nullable":true,"type":"string"},{"metadata":{},"name":"Rent_fee","nullable":true,"type":"string"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Appt_details","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"apartment_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Apartment_number","nullable":true,"type":"integer"},{"metadata":{},"name":"Type","nullable":true,"type":"string"},{"metadata":{},"name":"Rent_fee","nullable":true,"type":"float"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Appt_details","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- Apartment_number: integer (nullable = true)\n |-- Type: string (nullable = true)\n |-- Rent_fee: float (nullable = true)\n |-- Building_name: string (nullable = true)\n |-- Appt_details: string (nullable = true)\n\n+----------------+------------------+--------+--------------------+--------------------+\n|Apartment_number|              Type|Rent_fee|       Building_name|        Appt_details|\n+----------------+------------------+--------+--------------------+--------------------+\n|               1|Single Studio Flat|    8.61|            Koss Inc|In hac habitasse ...|\n|               2|    Single Bedroom|    1.98|     Wilderman-Ferry|Nulla ut erat id ...|\n|               3|  One Bedroom Flat|    5.23|            Yost Inc|Curabitur in libe...|\n|               4|  One Bedroom Flat|    2.63|         Klein-Robel|Morbi non lectus....|\n|               5|    Single Ensuite|    2.02|Hagenes, Block an...|Aliquam quis turp...|\n+----------------+------------------+--------+--------------------+--------------------+\nonly showing top 5 rows\n\n+----------------+------------------+--------+--------------------+--------------------+\n|Apartment_number|              Type|Rent_fee|       Building_name|        Appt_details|\n+----------------+------------------+--------+--------------------+--------------------+\n|               1|Single Studio Flat|    8.61|            Koss Inc|In hac habitasse ...|\n|               2|    Single Bedroom|    1.98|     Wilderman-Ferry|Nulla ut erat id ...|\n|               3|  One Bedroom Flat|    5.23|            Yost Inc|Curabitur in libe...|\n|               4|  One Bedroom Flat|    2.63|         Klein-Robel|Morbi non lectus....|\n|               5|    Single Ensuite|    2.02|Hagenes, Block an...|Aliquam quis turp...|\n+----------------+------------------+--------+--------------------+--------------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Apartment_number: integer (nullable = true)\n-- Type: string (nullable = true)\n-- Rent_fee: float (nullable = true)\n-- Building_name: string (nullable = true)\n-- Appt_details: string (nullable = true)\n\n+----------------+------------------+--------+--------------------+--------------------+\nApartment_number|              Type|Rent_fee|       Building_name|        Appt_details|\n+----------------+------------------+--------+--------------------+--------------------+\n               1|Single Studio Flat|    8.61|            Koss Inc|In hac habitasse ...|\n               2|    Single Bedroom|    1.98|     Wilderman-Ferry|Nulla ut erat id ...|\n               3|  One Bedroom Flat|    5.23|            Yost Inc|Curabitur in libe...|\n               4|  One Bedroom Flat|    2.63|         Klein-Robel|Morbi non lectus....|\n               5|    Single Ensuite|    2.02|Hagenes, Block an...|Aliquam quis turp...|\n+----------------+------------------+--------+--------------------+--------------------+\nonly showing top 5 rows\n\n+----------------+------------------+--------+--------------------+--------------------+\nApartment_number|              Type|Rent_fee|       Building_name|        Appt_details|\n+----------------+------------------+--------+--------------------+--------------------+\n               1|Single Studio Flat|    8.61|            Koss Inc|In hac habitasse ...|\n               2|    Single Bedroom|    1.98|     Wilderman-Ferry|Nulla ut erat id ...|\n               3|  One Bedroom Flat|    5.23|            Yost Inc|Curabitur in libe...|\n               4|  One Bedroom Flat|    2.63|         Klein-Robel|Morbi non lectus....|\n               5|    Single Ensuite|    2.02|Hagenes, Block an...|Aliquam quis turp...|\n+----------------+------------------+--------+--------------------+--------------------+\nonly showing top 5 rows\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["\n# import datetime\n# This is for date\ndateStr = datetime.date.today().strftime(\"%m-%d-%Y\")\nprint(dateStr)\n# this is for timestamp \ndateTimeStr = datetime.datetime.today().strftime(\"%m-%d-%Y %H:%M:%S\")\n\n# 1. get all the building  records\nbuilding_df = hivecontext.sql (\"select building_seq, Building_name, load_date from building_data order by load_date desc\")\n# 2. Now join the building DF with apartment_Df df to get the sequence of building \napartment_df_with_seq = apartment_df.join(building_df, \"Building_name\") \napartment_df_with_seq.show()\n# Get the latest record of building in case of many versions of apartment\nwindowSpec = W.partitionBy(\"building_seq\",\"Building_name\"  ).orderBy(col(\"load_date\").desc())\n\napartment_df_with_seq = apartment_df_with_seq.select('*', rank().over(windowSpec).alias('rank')) \\\n  .filter(col('rank') <= 1) \napartment_df_with_seq = apartment_df_with_seq.drop(\"rank\")\n \n# exclude all the rows with seq from apartment_df as they are already existing records\napartment_df = apartment_df.join(apartment_df_with_seq, \"Building_name\", \"leftanti\")\n \n# now it's time to insert new apartment data into table\n\n\n# Add building_seq column  -- foreign key\napartment_df = apartment_df.withColumn(\"building_seq\", lit(-1))  \n \n# Join the existing rows\nif apartment_df_with_seq is not None:\n  apartment_df_with_seq = apartment_df_with_seq.select(\"Apartment_number\", \"Type\", \"Rent_fee\",  \"building_seq\", \"Building_name\", \"Appt_details\"  )\n  apartment_df  = apartment_df.select(\"Apartment_number\", \"Type\", \"Rent_fee\",  \"building_seq\", \"Building_name\", \"Appt_details\"  )\n\n  final_join_df = unionAll(apartment_df, apartment_df_with_seq) \nelse:\n  final_join_df = apartment_df\n\n  \n# Add building_seq column \nwindowSpec = W.orderBy(\"Apartment_number\",\"Type\",\"Building_name\" )\nfinal_join_df = final_join_df.distinct().withColumn(\"apartment_seq\", F.row_number().over(windowSpec))  \n \ntimestamp = datetime.datetime.fromtimestamp(time.time())\ndateTimeStr = datetime.datetime.today().strftime(\"%m-%d-%Y %H:%M:%S\")\n\nfinal_join_df = final_join_df.withColumn(\"EventTimestamp\", lit(timestamp))\nfinal_join_df = final_join_df.withColumn(\"Load_date\", lit(dateTimeStr))\n\n\nfinal_join_df = final_join_df.select(\"apartment_seq\", \"Apartment_number\", \"Type\", \"Rent_fee\",  \"building_seq\", \"Building_name\", \"Appt_details\" ,\"EventTimestamp\", \"Load_date\" )\nfinal_join_df.printSchema() \nfinal_join_df.write.insertInto(\"apartment_data\")\n\napartment_table_count = hivecontext.sql(\"select * from apartment_data\")\nprint(apartment_table_count.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3e3d94b-0c2b-4384-ae82-7a33bbac7328"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"building_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"building_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"load_date","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"apartment_df_with_seq","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Apartment_number","nullable":true,"type":"integer"},{"metadata":{},"name":"Type","nullable":true,"type":"string"},{"metadata":{},"name":"Rent_fee","nullable":true,"type":"float"},{"metadata":{},"name":"building_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Appt_details","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"apartment_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Apartment_number","nullable":true,"type":"integer"},{"metadata":{},"name":"Type","nullable":true,"type":"string"},{"metadata":{},"name":"Rent_fee","nullable":true,"type":"float"},{"metadata":{},"name":"building_seq","nullable":false,"type":"integer"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Appt_details","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"final_join_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"apartment_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Apartment_number","nullable":true,"type":"integer"},{"metadata":{},"name":"Type","nullable":true,"type":"string"},{"metadata":{},"name":"Rent_fee","nullable":true,"type":"float"},{"metadata":{},"name":"building_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Appt_details","nullable":true,"type":"string"},{"metadata":{},"name":"EventTimestamp","nullable":false,"type":"timestamp"},{"metadata":{},"name":"Load_date","nullable":false,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"apartment_table_count","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"apartment_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Apartment_number","nullable":true,"type":"integer"},{"metadata":{},"name":"Type","nullable":true,"type":"string"},{"metadata":{},"name":"Rent_fee","nullable":true,"type":"float"},{"metadata":{},"name":"building_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Appt_details","nullable":true,"type":"string"},{"metadata":{},"name":"EventTimestamp","nullable":true,"type":"timestamp"},{"metadata":{},"name":"Load_date","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">03-22-2018\n+-------------+----------------+--------------+--------+--------------------+------------+-------------------+\n|Building_name|Apartment_number|          Type|Rent_fee|        Appt_details|building_seq|          load_date|\n+-------------+----------------+--------------+--------+--------------------+------------+-------------------+\n|Gutmann Group|              42|Single Ensuite|     8.3|In sagittis dui v...|           3|03-14-2018 15:14:15|\n+-------------+----------------+--------------+--------+--------------------+------------+-------------------+\n\nroot\n |-- apartment_seq: integer (nullable = true)\n |-- Apartment_number: integer (nullable = true)\n |-- Type: string (nullable = true)\n |-- Rent_fee: float (nullable = true)\n |-- building_seq: integer (nullable = true)\n |-- Building_name: string (nullable = true)\n |-- Appt_details: string (nullable = true)\n |-- EventTimestamp: timestamp (nullable = false)\n |-- Load_date: string (nullable = false)\n\n300\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">03-22-2018\n+-------------+----------------+--------------+--------+--------------------+------------+-------------------+\nBuilding_name|Apartment_number|          Type|Rent_fee|        Appt_details|building_seq|          load_date|\n+-------------+----------------+--------------+--------+--------------------+------------+-------------------+\nGutmann Group|              42|Single Ensuite|     8.3|In sagittis dui v...|           3|03-14-2018 15:14:15|\n+-------------+----------------+--------------+--------+--------------------+------------+-------------------+\n\nroot\n-- apartment_seq: integer (nullable = true)\n-- Apartment_number: integer (nullable = true)\n-- Type: string (nullable = true)\n-- Rent_fee: float (nullable = true)\n-- building_seq: integer (nullable = true)\n-- Building_name: string (nullable = true)\n-- Appt_details: string (nullable = true)\n-- EventTimestamp: timestamp (nullable = false)\n-- Load_date: string (nullable = false)\n\n300\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Get Contractor JSON from API\ndf = getSparkDataFrame(\"https://my.api.mockaroo.com/contractor_table.json?key=6af9c3e0\", contractor_schema)\ndf.printSchema()\ndf.show(5)\n\ncontractor_df = df.withColumn(\"PostCode\", udfValidatePostCode(\"Post_code\") )\ncontractor_df = contractor_df.select(contractor_df.Contract_id, contractor_df.Name, contractor_df.Address_line_1,  contractor_df.City, contractor_df.PostCode, contractor_df.Region)\ncontractor_df = contractor_df.withColumnRenamed(\"PostCode\", \"Post_code\") \n# Instantiation of DataTransformer class:\ncontractor_trans = op.DataFrameTransformer(contractor_df)\n# Replace NA with 0's\ncontractor_trans.replace_na(0.0, columns=\"*\")\n# Clear accents: clear_accents only from name column and not everywhere \ncontractor_trans.clear_accents(columns='*')\n# Remove special characters:  From all Columns \ncontractor_trans.remove_special_chars(columns=['Name', 'Address_line_1', 'City', 'Region'])\n# Create Temp table \ncontractor_df.registerTempTable('contractor_temp')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"116455fa-7b4d-45c1-b8ee-d09da332b8e5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Contract_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":false,"type":"string"},{"metadata":{},"name":"City","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"contractor_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Contract_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":false,"type":"string"},{"metadata":{},"name":"City","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- Contract_id: integer (nullable = false)\n |-- Name: string (nullable = true)\n |-- Address_line_1: string (nullable = false)\n |-- City: string (nullable = false)\n |-- Post_code: string (nullable = true)\n |-- Region: string (nullable = true)\n\n+-----------+-------------------+----------------+-------------+---------+--------------+\n|Contract_id|               Name|  Address_line_1|         City|Post_code|        Region|\n+-----------+-------------------+----------------+-------------+---------+--------------+\n|          1|      Louie MacKeeg| 67 Merry Center|Young America|    55564|     Minnesota|\n|          2|      Ramon Stanier|   9 Main Street|    Charlotte|    28256|North Carolina|\n|          3|Constance Garthland|53 Village Drive|   Montpelier|    05609|       Vermont|\n|          4|   Erika Willingale|3 Goodland Point|  Punta Gorda|    33982|       Florida|\n|          5|      Deina Jentges|2600 Melody Lane| Newport News|    23605|      Virginia|\n+-----------+-------------------+----------------+-------------+---------+--------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Contract_id: integer (nullable = false)\n-- Name: string (nullable = true)\n-- Address_line_1: string (nullable = false)\n-- City: string (nullable = false)\n-- Post_code: string (nullable = true)\n-- Region: string (nullable = true)\n\n+-----------+-------------------+----------------+-------------+---------+--------------+\nContract_id|               Name|  Address_line_1|         City|Post_code|        Region|\n+-----------+-------------------+----------------+-------------+---------+--------------+\n          1|      Louie MacKeeg| 67 Merry Center|Young America|    55564|     Minnesota|\n          2|      Ramon Stanier|   9 Main Street|    Charlotte|    28256|North Carolina|\n          3|Constance Garthland|53 Village Drive|   Montpelier|    05609|       Vermont|\n          4|   Erika Willingale|3 Goodland Point|  Punta Gorda|    33982|       Florida|\n          5|      Deina Jentges|2600 Melody Lane| Newport News|    23605|      Virginia|\n+-----------+-------------------+----------------+-------------+---------+--------------+\nonly showing top 5 rows\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# This is for date\ndateStr = datetime.date.today().strftime(\"%m-%d-%Y\")\nprint(dateStr)\n# this is for timestamp \ndateTimeStr = datetime.datetime.today().strftime(\"%m-%d-%Y %H:%M:%S\")\n\nselectContractorSql =\" select  Contract_id, Name, Address_line_1, City, Post_code, Region from contractor_data\"\n\nselectContractorSqlWithSeq = \" select contract_seq, Contract_id, Name, Address_line_1, City, Post_code, Region, EventTimestamp, Load_date from contractor_data\"\n\n# Get existing record from Contractor table\ncontractor_table_df = hivecontext.sql(selectContractorSql)\n\ncontractor_table_full_df = hivecontext.sql(selectContractorSqlWithSeq)\n\nexisting_rows = contractor_table_df.count()\n# get new rows from landlord_df by comparing it with Table data\nnew_df =contractor_df.subtract( contractor_table_df)  \nprint(new_df.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"441be011-d31e-4a35-a02c-6e2b182deaef"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"contractor_table_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Contract_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":true,"type":"string"},{"metadata":{},"name":"City","nullable":true,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"contractor_table_full_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"contract_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Contract_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":true,"type":"string"},{"metadata":{},"name":"City","nullable":true,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"},{"metadata":{},"name":"EventTimestamp","nullable":true,"type":"timestamp"},{"metadata":{},"name":"Load_date","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"new_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Contract_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":false,"type":"string"},{"metadata":{},"name":"City","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">03-22-2018\n50\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">03-22-2018\n50\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["contractor_existing_rows = None\nif (existing_rows > 0):\n  new_rows_df = new_df.withColumnRenamed(\"Name\", \"Name_1\").withColumnRenamed(\"Address_line_1\", \"Address_line_1_1\").withColumnRenamed(\"City\", \"City_1\") .withColumnRenamed(\"Post_code\", \"Post_code_1\") .withColumnRenamed(\"Region\", \"Region_1\")    \n\n  final_join_df = contractor_table_df.join(new_rows_df, contractor_table_df.Contract_id == contractor_df.Contract_id,  'outer') \\\n                  .select(contractor_table_df.Contract_id, \\\n                          F.when(new_rows_df.Name_1 != contractor_table_df.Name, \n                                 new_rows_df.Name_1 ).otherwise(contractor_table_df.Name).alias(\"Name\"), \n                          F.when(new_rows_df.Address_line_1_1 != contractor_table_df.Address_line_1, \n                                 new_rows_df.Address_line_1_1 ).otherwise(contractor_table_df.Address_line_1).alias(\"Address_line_1\"), \n                          F.when(new_rows_df.City_1 != contractor_table_df.City, \n                                 new_rows_df.City_1 ).otherwise(contractor_table_df.City).alias(\"City\"), \n                          F.when(new_rows_df.Post_code_1 != contractor_table_df.Post_code, \n                                 new_rows_df.Post_code_1 ).otherwise(contractor_table_df.Post_code).alias(\"Post_code\"), \n                          F.when(new_rows_df.Region_1 != contractor_table_df.Region, \n                                 new_rows_df.Region_1 ).otherwise(contractor_table_df.Region).alias(\"Region\")) \\\n                .filter(contractor_table_df.Contract_id.isNotNull()) \n  \n\n  # check If Id's already available in the table\n\n  contracctor_existing_rows_df = (contractor_table_full_df.select('Contract_id', 'Name')).intersect(new_df.select('Contract_id', 'Name'))\n  print(contracctor_existing_rows_df.count())\n  if (contracctor_existing_rows_df.count() > 0):\n    # it will have only Contract_id and Name\n    # get other columns also\n    contractor_existing_rows = contracctor_existing_rows_df.join(new_df, \"Contract_id\")\n    # join to get Contractor_seq column from contract table\n    contractor_existing_rows = contractor_existing_rows.join(contractor_table_full_df, \"Contract_id\")\n    # re-arrange the columns now\n    contractor_existing_rows = contractor_existing_rows.select(\"contract_seq\",  \"Contract_id\", \"Name\", \"Address_line_1\", \"City\", \"Post_code\", \"Region\" )\nelse:\n  final_join_df = new_df\n\n# Add landlord_seq column \nwindowSpec = W.orderBy(\"Contract_id\",\"Name\",\"City\",\"Region\")\nfinal_join_df = final_join_df.distinct().withColumn(\"contract_seq\", F.row_number().over(windowSpec))  \n# make sure column are in order\nfinal_join_df = final_join_df.select(\"contract_seq\", \"Contract_id\", \"Name\", \"Address_line_1\", \"City\", \"Post_code\", \"Region\" )\n\n# Join the existing rows\nif contractor_existing_rows is not None:\n  contractor_existing_rows.show()\n  final_join_df = unionAll(contractor_existing_rows, final_join_df) \n\n\ntimestamp = datetime.datetime.fromtimestamp(time.time())\ndateTimeStr = datetime.datetime.today().strftime(\"%m-%d-%Y %H:%M:%S\")\n\nfinal_join_df = final_join_df.withColumn(\"EventTimestamp\", lit(timestamp))\nfinal_join_df = final_join_df.withColumn(\"Load_date\", lit(dateTimeStr))\n\n\nfinal_join_df = final_join_df.select(\"contract_seq\", \"Contract_id\", \"Name\", \"Address_line_1\", \"City\", \"Post_code\", \"Region\", \"EventTimestamp\", \"Load_date\" )\nfinal_join_df.printSchema() \nfinal_join_df.write.insertInto(\"contractor_data\")\n\ncontractor_table_count = hivecontext.sql(\"select * from contractor_data\")\nprint(contractor_table_count.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"118e7712-82ae-4b98-a945-8a5f123f1e27"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"new_rows_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Contract_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Name_1","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1_1","nullable":false,"type":"string"},{"metadata":{},"name":"City_1","nullable":false,"type":"string"},{"metadata":{},"name":"Post_code_1","nullable":true,"type":"string"},{"metadata":{},"name":"Region_1","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"contracctor_existing_rows_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Contract_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Name","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"final_join_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"contract_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Contract_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":true,"type":"string"},{"metadata":{},"name":"City","nullable":true,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"},{"metadata":{},"name":"EventTimestamp","nullable":false,"type":"timestamp"},{"metadata":{},"name":"Load_date","nullable":false,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"contractor_table_count","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"contract_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Contract_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Name","nullable":true,"type":"string"},{"metadata":{},"name":"Address_line_1","nullable":true,"type":"string"},{"metadata":{},"name":"City","nullable":true,"type":"string"},{"metadata":{},"name":"Post_code","nullable":true,"type":"string"},{"metadata":{},"name":"Region","nullable":true,"type":"string"},{"metadata":{},"name":"EventTimestamp","nullable":true,"type":"timestamp"},{"metadata":{},"name":"Load_date","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">0\nroot\n |-- contract_seq: integer (nullable = true)\n |-- Contract_id: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- Address_line_1: string (nullable = true)\n |-- City: string (nullable = true)\n |-- Post_code: string (nullable = true)\n |-- Region: string (nullable = true)\n |-- EventTimestamp: timestamp (nullable = false)\n |-- Load_date: string (nullable = false)\n\n300\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0\nroot\n-- contract_seq: integer (nullable = true)\n-- Contract_id: integer (nullable = true)\n-- Name: string (nullable = true)\n-- Address_line_1: string (nullable = true)\n-- City: string (nullable = true)\n-- Post_code: string (nullable = true)\n-- Region: string (nullable = true)\n-- EventTimestamp: timestamp (nullable = false)\n-- Load_date: string (nullable = false)\n\n300\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Get Tenant JSON from API\ntenant_df = getSparkDataFrame(\"https://my.api.mockaroo.com/tenant.json?key=6af9c3e0\", tenant_schema)\ntenant_df.printSchema()\ntenant_df.show(5)\n# Instantiation of DataTransformer class:\ntenant_trans = op.DataFrameTransformer(tenant_df)\n# Replace NA with 0's\ntenant_trans.replace_na(0.0, columns=\"*\")\n# Clear accents: clear_accents only from name column and not everywhere \ntenant_trans.clear_accents(columns='*')\n# Remove special characters:  From all Columns \ntenant_trans.remove_special_chars(columns=['First_name', 'Last_name'])\n# Create Temp table \ntenant_df.registerTempTable('tenant_temp')\n\ntenants = tenant_df.rdd.map(lambda c: fixTenantRow(c))\ntenants_updated_df =  sqlContext.createDataFrame(tenants, tenant_schema)\ntenants_updated_df.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d0ac7fc-344c-44e4-bef0-5e5293b30c44"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"tenant_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Tenant_id","nullable":false,"type":"integer"},{"metadata":{},"name":"First_name","nullable":true,"type":"string"},{"metadata":{},"name":"Last_name","nullable":false,"type":"string"},{"metadata":{},"name":"Ssn","nullable":true,"type":"string"},{"metadata":{},"name":"Phone","nullable":true,"type":"string"},{"metadata":{},"name":"Email","nullable":true,"type":"string"},{"metadata":{},"name":"Mobile","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"tenants_updated_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Tenant_id","nullable":false,"type":"integer"},{"metadata":{},"name":"First_name","nullable":true,"type":"string"},{"metadata":{},"name":"Last_name","nullable":false,"type":"string"},{"metadata":{},"name":"Ssn","nullable":true,"type":"string"},{"metadata":{},"name":"Phone","nullable":true,"type":"string"},{"metadata":{},"name":"Email","nullable":true,"type":"string"},{"metadata":{},"name":"Mobile","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- Tenant_id: integer (nullable = false)\n |-- First_name: string (nullable = true)\n |-- Last_name: string (nullable = false)\n |-- Ssn: string (nullable = true)\n |-- Phone: string (nullable = true)\n |-- Email: string (nullable = true)\n |-- Mobile: string (nullable = true)\n\n+---------+----------+-----------+-----------+------------+--------------------+-------------------+\n|Tenant_id|First_name|  Last_name|        Ssn|       Phone|               Email|             Mobile|\n+---------+----------+-----------+-----------+------------+--------------------+-------------------+\n|        1|  Shirleen|Beiderbecke|535-68-3284|752 586 4683|sbeiderbecke0@his...|+385 (273) 365-2682|\n|        2|      Egon| Rosborough|411-35-0931|354 922 5547|erosborough1@baid...| +33 (291) 409-7565|\n|        3|Christalle|     Chiddy|681-73-1117|140 617 5713|  cchiddy2@phpbb.com|+351 (168) 313-8895|\n|        4| Dominique|     Govett|643-51-4738|395 812 8215|    dgovett3@gnu.org| +62 (546) 820-9801|\n|        5|    Allene|    Cornuau|428-33-9953|469 268 3750|acornuau4@oakley.com|+386 (926) 458-4565|\n+---------+----------+-----------+-----------+------------+--------------------+-------------------+\nonly showing top 5 rows\n\n+---------+----------+-----------+-----------+----------+--------------------+-------------+\n|Tenant_id|First_name|  Last_name|        Ssn|     Phone|               Email|       Mobile|\n+---------+----------+-----------+-----------+----------+--------------------+-------------+\n|        1|  Shirleen|Beiderbecke|535-68-3284|7525864683|sbeiderbecke0@his...|3852733652682|\n|        2|      Egon| Rosborough|411-35-0931|3549225547|erosborough1@baid...|  33291409756|\n|        3|Christalle|     Chiddy|681-73-1117|1406175713|  cchiddy2@phpbb.com|3511683138895|\n|        4| Dominique|     Govett|643-51-4738|3958128215|    dgovett3@gnu.org| 625468209801|\n|        5|    Allene|    Cornuau|428-33-9953|4692683750|acornuau4@oakley.com|3869264584565|\n+---------+----------+-----------+-----------+----------+--------------------+-------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Tenant_id: integer (nullable = false)\n-- First_name: string (nullable = true)\n-- Last_name: string (nullable = false)\n-- Ssn: string (nullable = true)\n-- Phone: string (nullable = true)\n-- Email: string (nullable = true)\n-- Mobile: string (nullable = true)\n\n+---------+----------+-----------+-----------+------------+--------------------+-------------------+\nTenant_id|First_name|  Last_name|        Ssn|       Phone|               Email|             Mobile|\n+---------+----------+-----------+-----------+------------+--------------------+-------------------+\n        1|  Shirleen|Beiderbecke|535-68-3284|752 586 4683|sbeiderbecke0@his...|+385 (273) 365-2682|\n        2|      Egon| Rosborough|411-35-0931|354 922 5547|erosborough1@baid...| +33 (291) 409-7565|\n        3|Christalle|     Chiddy|681-73-1117|140 617 5713|  cchiddy2@phpbb.com|+351 (168) 313-8895|\n        4| Dominique|     Govett|643-51-4738|395 812 8215|    dgovett3@gnu.org| +62 (546) 820-9801|\n        5|    Allene|    Cornuau|428-33-9953|469 268 3750|acornuau4@oakley.com|+386 (926) 458-4565|\n+---------+----------+-----------+-----------+------------+--------------------+-------------------+\nonly showing top 5 rows\n\n+---------+----------+-----------+-----------+----------+--------------------+-------------+\nTenant_id|First_name|  Last_name|        Ssn|     Phone|               Email|       Mobile|\n+---------+----------+-----------+-----------+----------+--------------------+-------------+\n        1|  Shirleen|Beiderbecke|535-68-3284|7525864683|sbeiderbecke0@his...|3852733652682|\n        2|      Egon| Rosborough|411-35-0931|3549225547|erosborough1@baid...|  33291409756|\n        3|Christalle|     Chiddy|681-73-1117|1406175713|  cchiddy2@phpbb.com|3511683138895|\n        4| Dominique|     Govett|643-51-4738|3958128215|    dgovett3@gnu.org| 625468209801|\n        5|    Allene|    Cornuau|428-33-9953|4692683750|acornuau4@oakley.com|3869264584565|\n+---------+----------+-----------+-----------+----------+--------------------+-------------+\nonly showing top 5 rows\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# This is for date\ndateStr = datetime.date.today().strftime(\"%m-%d-%Y\")\nprint(dateStr)\n# this is for timestamp \ndateTimeStr = datetime.datetime.today().strftime(\"%m-%d-%Y %H:%M:%S\")\n\nselectTenantSql =\" select  Tenant_id ,First_name ,Last_name ,Ssn ,Phone  ,Email  ,Mobile from tenant_data\"\n\nselectTenantSqlWithSeq = \" select tenant_seq, Tenant_id ,First_name ,Last_name ,Ssn, Phone  ,Email  ,Mobile, EventTimestamp, Load_date from tenant_data\"\n\n# Get existing record from Contractor table\ntenant_table_df = hivecontext.sql(selectTenantSql)\n\ntenant_table_full_df = hivecontext.sql(selectTenantSqlWithSeq)\n\nexisting_rows = tenant_table_df.count()\n# get new rows from landlord_df by comparing it with Table data\nnew_df =tenant_df.subtract( tenant_table_df)  \nprint(new_df.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"368fc612-0724-46d6-b21b-c91155064003"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"tenant_table_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Tenant_id","nullable":true,"type":"integer"},{"metadata":{},"name":"First_name","nullable":true,"type":"string"},{"metadata":{},"name":"Last_name","nullable":true,"type":"string"},{"metadata":{},"name":"Ssn","nullable":true,"type":"string"},{"metadata":{},"name":"Phone","nullable":true,"type":"string"},{"metadata":{},"name":"Email","nullable":true,"type":"string"},{"metadata":{},"name":"Mobile","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"tenant_table_full_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"tenant_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Tenant_id","nullable":true,"type":"integer"},{"metadata":{},"name":"First_name","nullable":true,"type":"string"},{"metadata":{},"name":"Last_name","nullable":true,"type":"string"},{"metadata":{},"name":"Ssn","nullable":true,"type":"string"},{"metadata":{},"name":"Phone","nullable":true,"type":"string"},{"metadata":{},"name":"Email","nullable":true,"type":"string"},{"metadata":{},"name":"Mobile","nullable":true,"type":"string"},{"metadata":{},"name":"EventTimestamp","nullable":true,"type":"timestamp"},{"metadata":{},"name":"Load_date","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"new_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Tenant_id","nullable":false,"type":"integer"},{"metadata":{},"name":"First_name","nullable":true,"type":"string"},{"metadata":{},"name":"Last_name","nullable":false,"type":"string"},{"metadata":{},"name":"Ssn","nullable":true,"type":"string"},{"metadata":{},"name":"Phone","nullable":true,"type":"string"},{"metadata":{},"name":"Email","nullable":true,"type":"string"},{"metadata":{},"name":"Mobile","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">03-22-2018\n50\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">03-22-2018\n50\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["tenant_existing_rows = None\nif (existing_rows > 0):\n  new_rows_df = new_df.withColumnRenamed(\"First_name\", \"First_name_1\").withColumnRenamed(\"Last_name\", \"Last_name_1\").withColumnRenamed(\"Ssn\", \"Ssn_1\") .withColumnRenamed(\"Phone\", \"Phone_1\") .withColumnRenamed(\"Email\", \"Email_1\").withColumnRenamed(\"Mobile\", \"Mobile_1\")    \n\n  final_join_df = tenant_table_df.join(new_rows_df, tenant_table_df.Tenant_id == tenant_df.Tenant_id,  'outer') \\\n                  .select(tenant_table_df.Tenant_id, \\\n                          F.when(new_rows_df.First_name_1 != tenant_table_df.First_name, \n                                 new_rows_df.First_name_1 ).otherwise(tenant_table_df.First_name).alias(\"First_name\"), \n                          F.when(new_rows_df.Last_name_1 != tenant_table_df.Last_name, \n                                 new_rows_df.Last_name_1 ).otherwise(tenant_table_df.Last_name).alias(\"Last_name\"), \n                          F.when(new_rows_df.Ssn_1 != tenant_table_df.Ssn, \n                                 new_rows_df.Ssn_1 ).otherwise(tenant_table_df.Ssn).alias(\"Ssn\"), \n                          F.when(new_rows_df.Phone_1 != tenant_table_df.Phone, \n                                 new_rows_df.Phone_1 ).otherwise(tenant_table_df.Phone).alias(\"Phone\"), \n                          F.when(new_rows_df.Email_1 != tenant_table_df.Email, \n                                 new_rows_df.Email_1 ).otherwise(tenant_table_df.Email).alias(\"Email\"), \n                          F.when(new_rows_df.Mobile_1 != tenant_table_df.Mobile, \n                                 new_rows_df.Mobile_1 ).otherwise(tenant_table_df.Mobile).alias(\"Mobile\") ) \\\n                .filter(tenant_table_df.Tenant_id.isNotNull()) \n  \n\n  # check If Id's already available in the table\n\n  tenant_existing_rows_df = (tenant_table_full_df.select('Tenant_id', 'First_name')).intersect(new_df.select('Tenant_id', 'First_name'))\n  print(tenant_existing_rows_df.count())\n  if (tenant_existing_rows_df.count() > 0):\n    # it will have only Contract_id and Name\n    # get other columns also\n    tenant_existing_rows = tenant_existing_rows_df.join(new_df, \"Tenant_id\")\n    # join to get Contractor_seq column from contract table\n    tenant_existing_rows = tenant_existing_rows.join(tenant_table_full_df, \"Tenant_id\")\n    # re-arrange the columns now\n    tenant_existing_rows = tenant_existing_rows.select(\"tenant_seq\",  \"Tenant_id\", \"First_name\", \"Last_name\" ,\"Ssn\"  , \"Phone\"  ,\"Email\"  ,\"Mobile\" )\nelse:\n  final_join_df = new_df\n\n# Add landlord_seq column \nwindowSpec = W.orderBy(\"Tenant_id\", \"First_name\", \"Last_name\" ,\"Ssn\"  )\nfinal_join_df = final_join_df.distinct().withColumn(\"tenant_seq\", F.row_number().over(windowSpec))  \n# make sure column are in order\nfinal_join_df = final_join_df.select(\"tenant_seq\", \"Tenant_id\", \"First_name\", \"Last_name\" ,\"Ssn\"  , \"Phone\"  ,\"Email\"  ,\"Mobile\" )\n\n# Join the existing rows\nif tenant_existing_rows is not None:\n  tenant_existing_rows.show()\n  final_join_df = unionAll(tenant_existing_rows, final_join_df) \n\n\ntimestamp = datetime.datetime.fromtimestamp(time.time())\ndateTimeStr = datetime.datetime.today().strftime(\"%m-%d-%Y %H:%M:%S\")\n\nfinal_join_df = final_join_df.withColumn(\"EventTimestamp\", lit(timestamp))\nfinal_join_df = final_join_df.withColumn(\"Load_date\", lit(dateTimeStr))\n\n\nfinal_join_df = final_join_df.select(\"tenant_seq\", \"Tenant_id\", \"First_name\", \"Last_name\" ,\"Ssn\"  , \"Phone\"  ,\"Email\"  ,\"Mobile\" ,\"EventTimestamp\", \"Load_date\" )\nfinal_join_df.printSchema() \nfinal_join_df.write.insertInto(\"tenant_data\")\n\ntenant_table_count = hivecontext.sql(\"select * from tenant_data\")\nprint(tenant_table_count.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85266516-d3ff-44f3-8ffd-3d3eba975b62"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"new_rows_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Tenant_id","nullable":false,"type":"integer"},{"metadata":{},"name":"First_name_1","nullable":true,"type":"string"},{"metadata":{},"name":"Last_name_1","nullable":false,"type":"string"},{"metadata":{},"name":"Ssn_1","nullable":true,"type":"string"},{"metadata":{},"name":"Phone_1","nullable":true,"type":"string"},{"metadata":{},"name":"Email_1","nullable":true,"type":"string"},{"metadata":{},"name":"Mobile_1","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"tenant_existing_rows_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Tenant_id","nullable":false,"type":"integer"},{"metadata":{},"name":"First_name","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"final_join_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"tenant_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Tenant_id","nullable":true,"type":"integer"},{"metadata":{},"name":"First_name","nullable":true,"type":"string"},{"metadata":{},"name":"Last_name","nullable":true,"type":"string"},{"metadata":{},"name":"Ssn","nullable":true,"type":"string"},{"metadata":{},"name":"Phone","nullable":true,"type":"string"},{"metadata":{},"name":"Email","nullable":true,"type":"string"},{"metadata":{},"name":"Mobile","nullable":true,"type":"string"},{"metadata":{},"name":"EventTimestamp","nullable":false,"type":"timestamp"},{"metadata":{},"name":"Load_date","nullable":false,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"tenant_table_count","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"tenant_seq","nullable":true,"type":"integer"},{"metadata":{},"name":"Tenant_id","nullable":true,"type":"integer"},{"metadata":{},"name":"First_name","nullable":true,"type":"string"},{"metadata":{},"name":"Last_name","nullable":true,"type":"string"},{"metadata":{},"name":"Ssn","nullable":true,"type":"string"},{"metadata":{},"name":"Phone","nullable":true,"type":"string"},{"metadata":{},"name":"Email","nullable":true,"type":"string"},{"metadata":{},"name":"Mobile","nullable":true,"type":"string"},{"metadata":{},"name":"EventTimestamp","nullable":true,"type":"timestamp"},{"metadata":{},"name":"Load_date","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">0\nroot\n |-- tenant_seq: integer (nullable = true)\n |-- Tenant_id: integer (nullable = true)\n |-- First_name: string (nullable = true)\n |-- Last_name: string (nullable = true)\n |-- Ssn: string (nullable = true)\n |-- Phone: string (nullable = true)\n |-- Email: string (nullable = true)\n |-- Mobile: string (nullable = true)\n |-- EventTimestamp: timestamp (nullable = false)\n |-- Load_date: string (nullable = false)\n\n150\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0\nroot\n-- tenant_seq: integer (nullable = true)\n-- Tenant_id: integer (nullable = true)\n-- First_name: string (nullable = true)\n-- Last_name: string (nullable = true)\n-- Ssn: string (nullable = true)\n-- Phone: string (nullable = true)\n-- Email: string (nullable = true)\n-- Mobile: string (nullable = true)\n-- EventTimestamp: timestamp (nullable = false)\n-- Load_date: string (nullable = false)\n\n150\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Get Lease JSON from API\nlease_df = getSparkDataFrame(\"https://my.api.mockaroo.com/lease.json?key=6af9c3e0\", lease_schema)\nlease_df.printSchema()\nlease_df.show(5)\n# Instantiation of DataTransformer class:\nlease_trans = op.DataFrameTransformer(lease_df)\n# Replace NA with 0's\nlease_trans.replace_na(0.0, columns=\"*\")\n# Tranform string date format:\nlease_trans.date_transform(columns=\"Start\" ,\n                          current_format=\"dd-MMM-yyyy\",\n                          output_format=\"dd-mm-yy hh:mi:ss\")\n# Clear accents: clear_accents only from name column and not everywhere \nlease_trans.clear_accents(columns='*') \n\n## Formatting is pending for Start And End, when it's converted hh:mm::ss is taken as default value\n## Is it okay to convert? \n## Optimus is not working for \nfrom pyspark.sql.functions import unix_timestamp, from_unixtime\ndf2 = lease_df.select('Start', from_unixtime(unix_timestamp('Start', 'dd-MMM-yyyy')).alias('date'))\ndf2.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"73ab1ed5-0c23-4295-b1ce-17b86f5de65a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"lease_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Lease_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Start","nullable":true,"type":"string"},{"metadata":{},"name":"End","nullable":false,"type":"string"},{"metadata":{},"name":"Deposit","nullable":true,"type":"string"},{"metadata":{},"name":"Tenant_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Apartment_id","nullable":true,"type":"integer"}],"type":"struct"},"tableIdentifier":null},{"name":"df2","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Start","nullable":true,"type":"string"},{"metadata":{},"name":"date","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- Lease_id: integer (nullable = false)\n |-- Start: string (nullable = true)\n |-- End: string (nullable = false)\n |-- Deposit: string (nullable = true)\n |-- Tenant_id: integer (nullable = true)\n |-- Apartment_id: integer (nullable = true)\n\n+--------+-----------+-----------+--------+---------+------------+\n|Lease_id|      Start|        End| Deposit|Tenant_id|Apartment_id|\n+--------+-----------+-----------+--------+---------+------------+\n|       1|09-Nov-2011|05-Sep-2015|$1598.20|        1|           1|\n|       2|17-Sep-2017|12-Jun-2013| $706.33|        2|           2|\n|       3|02-Jul-2010|12-Sep-2016|$1006.06|        3|           3|\n|       4|09-May-2015|05-Aug-2012| $127.31|        4|           4|\n|       5|18-Nov-2015|09-Oct-2017|$1214.02|        5|           5|\n+--------+-----------+-----------+--------+---------+------------+\nonly showing top 5 rows\n\n+-----------+-------------------+\n|      Start|               date|\n+-----------+-------------------+\n|09-Nov-2011|2011-11-09 00:00:00|\n|17-Sep-2017|2017-09-17 00:00:00|\n|02-Jul-2010|2010-07-02 00:00:00|\n|09-May-2015|2015-05-09 00:00:00|\n|18-Nov-2015|2015-11-18 00:00:00|\n+-----------+-------------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Lease_id: integer (nullable = false)\n-- Start: string (nullable = true)\n-- End: string (nullable = false)\n-- Deposit: string (nullable = true)\n-- Tenant_id: integer (nullable = true)\n-- Apartment_id: integer (nullable = true)\n\n+--------+-----------+-----------+--------+---------+------------+\nLease_id|      Start|        End| Deposit|Tenant_id|Apartment_id|\n+--------+-----------+-----------+--------+---------+------------+\n       1|09-Nov-2011|05-Sep-2015|$1598.20|        1|           1|\n       2|17-Sep-2017|12-Jun-2013| $706.33|        2|           2|\n       3|02-Jul-2010|12-Sep-2016|$1006.06|        3|           3|\n       4|09-May-2015|05-Aug-2012| $127.31|        4|           4|\n       5|18-Nov-2015|09-Oct-2017|$1214.02|        5|           5|\n+--------+-----------+-----------+--------+---------+------------+\nonly showing top 5 rows\n\n+-----------+-------------------+\n      Start|               date|\n+-----------+-------------------+\n09-Nov-2011|2011-11-09 00:00:00|\n17-Sep-2017|2017-09-17 00:00:00|\n02-Jul-2010|2010-07-02 00:00:00|\n09-May-2015|2015-05-09 00:00:00|\n18-Nov-2015|2015-11-18 00:00:00|\n+-----------+-------------------+\nonly showing top 5 rows\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Get Rent JSON from API\nrent_df = getSparkDataFrame(\"https://my.api.mockaroo.com/rent.json?key=6af9c3e0\", rent_schema)\nrent_df.printSchema()\n# Instantiation of DataTransformer class:\nrent_trans = op.DataFrameTransformer(rent_df)\n# Replace NA with 0's\nrent_trans.replace_na(0.0, columns=\"*\")\n# Tranform string date format:\n\n## This conversion is not working\nrent_trans.date_transform(columns=\"Due_date\" ,\n                          current_format=\"yyyy-mm-dd hh:mi:ss\",\n                          output_format=\"dd-mm-yy hh24:mi:ss\")\n# Clear accents: clear_accents only from name column and not everywhere \nrent_trans.clear_accents(columns='*') \n \n# cast the Pay_date to timestamp  in specific format\nrent_df = rent_df.select('Rent_id', 'Rent_fee', 'Late_fee',   from_unixtime(unix_timestamp('Due_date', 'yyyy-MM-dd HH:mm:ss'), 'dd-MM-yyyy HH:mm:ss').alias('DueDate'), 'Lease_id', 'Pay_id')\nrent_df = rent_df.withColumnRenamed('DueDate', 'Due_date')\n\nrent_df.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2deb116-acf9-49a1-82fe-6e994d549d5b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"rent_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Rent_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Rent_fee","nullable":true,"type":"string"},{"metadata":{},"name":"Late_fee","nullable":false,"type":"string"},{"metadata":{},"name":"Due_date","nullable":true,"type":"string"},{"metadata":{},"name":"Lease_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Pay_id","nullable":true,"type":"integer"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- Rent_id: integer (nullable = false)\n |-- Rent_fee: string (nullable = true)\n |-- Late_fee: string (nullable = false)\n |-- Due_date: timestamp (nullable = true)\n |-- Lease_id: integer (nullable = true)\n |-- Pay_id: integer (nullable = true)\n\n+-------+--------+--------+-------------------+--------+------+\n|Rent_id|Rent_fee|Late_fee|           Due_date|Lease_id|Pay_id|\n+-------+--------+--------+-------------------+--------+------+\n|      1| $758.16|$1345.41|27-01-2017 08:58:38|      29|   239|\n|      2| $821.11|$2115.87|19-12-2017 03:30:59|     770|   243|\n|      3| $727.03|$2128.63|06-08-2017 01:49:19|     652|    12|\n|      4| $890.42|$2016.84|11-04-2017 06:55:59|     813|   796|\n|      5| $985.00|$1210.15|27-06-2017 22:46:13|     532|   229|\n+-------+--------+--------+-------------------+--------+------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Rent_id: integer (nullable = false)\n-- Rent_fee: string (nullable = true)\n-- Late_fee: string (nullable = false)\n-- Due_date: timestamp (nullable = true)\n-- Lease_id: integer (nullable = true)\n-- Pay_id: integer (nullable = true)\n\n+-------+--------+--------+-------------------+--------+------+\nRent_id|Rent_fee|Late_fee|           Due_date|Lease_id|Pay_id|\n+-------+--------+--------+-------------------+--------+------+\n      1| $758.16|$1345.41|27-01-2017 08:58:38|      29|   239|\n      2| $821.11|$2115.87|19-12-2017 03:30:59|     770|   243|\n      3| $727.03|$2128.63|06-08-2017 01:49:19|     652|    12|\n      4| $890.42|$2016.84|11-04-2017 06:55:59|     813|   796|\n      5| $985.00|$1210.15|27-06-2017 22:46:13|     532|   229|\n+-------+--------+--------+-------------------+--------+------+\nonly showing top 5 rows\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Get Payment JSON from API\npayment_df = getSparkDataFrame(\"https://my.api.mockaroo.com/payment.json?key=6af9c3e0\", payment_schema)\npayment_df.printSchema()\n# Instantiation of DataTransformer class:\npayment_trans = op.DataFrameTransformer(payment_df)\n# Replace NA with 0's\npayment_trans.replace_na(0.0, columns=\"*\")\n# Tranform string date format:\n\n# cast the due_date to timestamp  in specific format\npayment_df = payment_df.select('Payment_id', from_unixtime(unix_timestamp('Pay_date', 'yyyy-MM-dd HH:mm:ss'), 'dd-MM-yyyy HH:mm:ss').alias('PayDate'), 'Pay_amount', 'Method', 'Rent_id')\nrent_df = rent_df.withColumnRenamed('PayDate', 'Pay_date')\npayment_df.show(5)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f98a7219-e371-411a-9389-d26fe2dd05b6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"payment_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Payment_id","nullable":false,"type":"integer"},{"metadata":{},"name":"PayDate","nullable":true,"type":"string"},{"metadata":{},"name":"Pay_amount","nullable":false,"type":"string"},{"metadata":{},"name":"Method","nullable":true,"type":"string"},{"metadata":{},"name":"Rent_id","nullable":true,"type":"integer"}],"type":"struct"},"tableIdentifier":null},{"name":"rent_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Rent_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Rent_fee","nullable":true,"type":"string"},{"metadata":{},"name":"Late_fee","nullable":false,"type":"string"},{"metadata":{},"name":"Due_date","nullable":true,"type":"string"},{"metadata":{},"name":"Lease_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Pay_id","nullable":true,"type":"integer"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- Payment_id: integer (nullable = false)\n |-- Pay_date: timestamp (nullable = true)\n |-- Pay_amount: string (nullable = false)\n |-- Method: string (nullable = true)\n |-- Rent_id: integer (nullable = true)\n\n+----------+-------------------+----------+------+-------+\n|Payment_id|            PayDate|Pay_amount|Method|Rent_id|\n+----------+-------------------+----------+------+-------+\n|         1|02-08-2017 21:39:37|   $558.96|Cheque|    853|\n|         2|11-01-2017 17:23:44|  $1999.42|  Cash|    639|\n|         3|29-05-2017 03:24:32|  $2438.93|  Cash|    797|\n|         4|08-01-2017 23:31:19|  $1112.16|  Cash|    877|\n|         5|24-04-2017 22:47:39|  $2916.19|  Cash|    956|\n+----------+-------------------+----------+------+-------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Payment_id: integer (nullable = false)\n-- Pay_date: timestamp (nullable = true)\n-- Pay_amount: string (nullable = false)\n-- Method: string (nullable = true)\n-- Rent_id: integer (nullable = true)\n\n+----------+-------------------+----------+------+-------+\nPayment_id|            PayDate|Pay_amount|Method|Rent_id|\n+----------+-------------------+----------+------+-------+\n         1|02-08-2017 21:39:37|   $558.96|Cheque|    853|\n         2|11-01-2017 17:23:44|  $1999.42|  Cash|    639|\n         3|29-05-2017 03:24:32|  $2438.93|  Cash|    797|\n         4|08-01-2017 23:31:19|  $1112.16|  Cash|    877|\n         5|24-04-2017 22:47:39|  $2916.19|  Cash|    956|\n+----------+-------------------+----------+------+-------+\nonly showing top 5 rows\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Get Apartment maintenance JSON from API\napt_maintenance_df = getSparkDataFrameWithoutLFChar(\"https://my.api.mockaroo.com/apartment_maintenance.json?key=6af9c3e0\", apt_maintenance_schema)\napt_maintenance_df.printSchema()\n# Instantiation of DataTransformer class:\napt_main_trans = op.DataFrameTransformer(apt_maintenance_df)\n# Replace NA with 0's\napt_main_trans.replace_na(0.0, columns=\"*\")\n# Clear accents: clear_accents only from name column and not everywhere \napt_main_trans.clear_accents(columns='*')\n# Remove special characters:  From all Columns \napt_main_trans.remove_special_chars(columns=['Resolution', 'Status'])\n# Create Temp table \napt_maintenance_df.registerTempTable('apt_maintenance_temp')\n\n# cast the Mdate to timestamp  in specific format\napt_maintenance_df = apt_maintenance_df.select('Maintenance_id', 'Apartment_number', from_unixtime(unix_timestamp('Mdate', 'yyyy-MM-dd HH:mm:ss'), 'dd-MM-yyyy HH:mm:ss').alias('M_date'), 'Issue_reported', 'Contractor_id', 'Resolution', 'Status', 'Charges_incurred')\napt_maintenance_df = apt_maintenance_df.withColumnRenamed('M_date', 'Mdate')\n\napt_maintenance_df.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d9a7ac1-162d-4bef-aaa3-f72afd68c369"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"apt_maintenance_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Maintenance_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Apartment_number","nullable":true,"type":"integer"},{"metadata":{},"name":"Mdate","nullable":true,"type":"string"},{"metadata":{},"name":"Issue_reported","nullable":true,"type":"string"},{"metadata":{},"name":"Contractor_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Resolution","nullable":true,"type":"string"},{"metadata":{},"name":"Status","nullable":true,"type":"string"},{"metadata":{},"name":"Charges_incurred","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- Maintenance_id: integer (nullable = false)\n |-- Apartment_number: integer (nullable = true)\n |-- Mdate: string (nullable = false)\n |-- Issue_reported: string (nullable = true)\n |-- Contractor_id: integer (nullable = true)\n |-- Resolution: string (nullable = true)\n |-- Status: string (nullable = true)\n |-- Charges_incurred: string (nullable = true)\n\n+--------------+----------------+-------------------+--------------------+-------------+--------------------+--------+----------------+\n|Maintenance_id|Apartment_number|              Mdate|      Issue_reported|Contractor_id|          Resolution|  Status|Charges_incurred|\n+--------------+----------------+-------------------+--------------------+-------------+--------------------+--------+----------------+\n|             1|             716|12-06-2017 16:01:45|Quisque porta vol...|          745|                null|  Closed|         £405.40|\n|             2|             330|05-05-2017 15:40:12|Etiam vel augue. ...|          553|Maecenas leo odio...|Assigned|         £383.03|\n|             3|             548|28-01-2017 09:08:48|Vestibulum quam s...|          395|Maecenas tristiqu...|  Closed|         £761.91|\n|             4|             528|16-04-2017 12:21:38|In quis justo. Ma...|          872|Phasellus in feli...|    Open|         £151.69|\n|             5|             780|10-07-2017 04:29:47|Nulla ut erat id ...|           52|Maecenas ut massa...|  Closed|         £408.35|\n+--------------+----------------+-------------------+--------------------+-------------+--------------------+--------+----------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Maintenance_id: integer (nullable = false)\n-- Apartment_number: integer (nullable = true)\n-- Mdate: string (nullable = false)\n-- Issue_reported: string (nullable = true)\n-- Contractor_id: integer (nullable = true)\n-- Resolution: string (nullable = true)\n-- Status: string (nullable = true)\n-- Charges_incurred: string (nullable = true)\n\n+--------------+----------------+-------------------+--------------------+-------------+--------------------+--------+----------------+\nMaintenance_id|Apartment_number|              Mdate|      Issue_reported|Contractor_id|          Resolution|  Status|Charges_incurred|\n+--------------+----------------+-------------------+--------------------+-------------+--------------------+--------+----------------+\n             1|             716|12-06-2017 16:01:45|Quisque porta vol...|          745|                null|  Closed|         £405.40|\n             2|             330|05-05-2017 15:40:12|Etiam vel augue. ...|          553|Maecenas leo odio...|Assigned|         £383.03|\n             3|             548|28-01-2017 09:08:48|Vestibulum quam s...|          395|Maecenas tristiqu...|  Closed|         £761.91|\n             4|             528|16-04-2017 12:21:38|In quis justo. Ma...|          872|Phasellus in feli...|    Open|         £151.69|\n             5|             780|10-07-2017 04:29:47|Nulla ut erat id ...|           52|Maecenas ut massa...|  Closed|         £408.35|\n+--------------+----------------+-------------------+--------------------+-------------+--------------------+--------+----------------+\nonly showing top 5 rows\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["#Create ApartmentMaintenance Hive Table\n#\nhivecontext.sql(\"CREATE TABLE IF NOT EXISTS apartment_maintenance (Maintenance_id INT,  Apartment_number  INT,  Mdate  STRING,  Issue_reported  STRING, Contractor_id  INT, Resolution  STRING, Status  STRING, Charges_incurred  STRING,  EventTimestamp timestamp )\")\n\n# Insert/Overwrite the records in building hive table\nhivecontext.sql(\"insert overwrite table apartment_maintenance select Maintenance_id, Apartment_number,  Mdate, Issue_reported, Contractor_id, Resolution, Status, Charges_incurred, from_unixtime(unix_timestamp()) from apt_maintenance_temp\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92b5b575-cedb-4916-8e6d-056e14c2f3d4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">86</span><span class=\"ansired\">]: </span>DataFrame[]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">86</span><span class=\"ansired\">]: </span>DataFrame[]\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# Get Building maintenance JSON from API\nbuilding_maintenance_df = getSparkDataFrameWithoutLFChar(\"https://my.api.mockaroo.com/building_maintenance.json?key=6af9c3e0\", building_maintenance_schema)\nbuilding_maintenance_df.printSchema()\n# Instantiation of DataTransformer class:\nbuilding_main_trans = op.DataFrameTransformer(building_maintenance_df)\n# Replace NA with 0's\nbuilding_main_trans.replace_na(0.0, columns=\"*\")\n# Clear accents: clear_accents only from name column and not everywhere \nbuilding_main_trans.clear_accents(columns='*')\n# Remove special characters:  From all Columns \nbuilding_main_trans.remove_special_chars(columns=['Issue_reported', 'Resolution', 'Status'])\n\n# cast the Ndate to timestamp  in specific format\nbuilding_maintenance_df = building_maintenance_df.select('Maintenance_id', 'Building_name', from_unixtime(unix_timestamp('Ndate', 'yyyy-MM-dd HH:mm:ss'), 'dd-MM-yyyy HH:mm:ss').alias('N_date'), 'Issue_reported', 'Contractor_id', 'Resolution', 'Status')\nbuilding_maintenance_df = building_maintenance_df.withColumnRenamed('N_date', 'Ndate')\nbuilding_maintenance_df.show(5)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bda71550-6544-4e78-a190-0609ccf3aad4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"building_maintenance_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"Maintenance_id","nullable":false,"type":"integer"},{"metadata":{},"name":"Building_name","nullable":true,"type":"string"},{"metadata":{},"name":"Ndate","nullable":true,"type":"string"},{"metadata":{},"name":"Issue_reported","nullable":true,"type":"string"},{"metadata":{},"name":"Contractor_id","nullable":true,"type":"integer"},{"metadata":{},"name":"Resolution","nullable":true,"type":"string"},{"metadata":{},"name":"Status","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- Maintenance_id: integer (nullable = false)\n |-- Building_name: string (nullable = true)\n |-- Ndate: string (nullable = false)\n |-- Issue_reported: string (nullable = true)\n |-- Contractor_id: integer (nullable = true)\n |-- Resolution: string (nullable = true)\n |-- Status: string (nullable = true)\n\n+--------------+--------------------+-------------------+--------------------+-------------+--------------------+--------+\n|Maintenance_id|       Building_name|              Ndate|      Issue_reported|Contractor_id|          Resolution|  Status|\n+--------------+--------------------+-------------------+--------------------+-------------+--------------------+--------+\n|             1|Auer, Johns and A...|20-11-2017 23:58:59|Curabitur in libe...|          535|Nam ultrices, lib...|  Closed|\n|             2|Howe, Frami and Hand|08-03-2017 00:17:38|Maecenas ut massa...|          685|Donec diam neque,...|  Closed|\n|             3|          Rohan-Moen|22-02-2017 23:50:09|Cras non velit ne...|          928|Nullam sit amet t...|Assigned|\n|             4|       Swift-Goldner|27-01-2017 00:32:52|Vestibulum ac est...|           73|In hac habitasse ...|  Closed|\n|             5|Crist, Armstrong ...|25-05-2017 21:57:27|Duis aliquam conv...|          978|Curabitur gravida...|  Closed|\n+--------------+--------------------+-------------------+--------------------+-------------+--------------------+--------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Maintenance_id: integer (nullable = false)\n-- Building_name: string (nullable = true)\n-- Ndate: string (nullable = false)\n-- Issue_reported: string (nullable = true)\n-- Contractor_id: integer (nullable = true)\n-- Resolution: string (nullable = true)\n-- Status: string (nullable = true)\n\n+--------------+--------------------+-------------------+--------------------+-------------+--------------------+--------+\nMaintenance_id|       Building_name|              Ndate|      Issue_reported|Contractor_id|          Resolution|  Status|\n+--------------+--------------------+-------------------+--------------------+-------------+--------------------+--------+\n             1|Auer, Johns and A...|20-11-2017 23:58:59|Curabitur in libe...|          535|Nam ultrices, lib...|  Closed|\n             2|Howe, Frami and Hand|08-03-2017 00:17:38|Maecenas ut massa...|          685|Donec diam neque,...|  Closed|\n             3|          Rohan-Moen|22-02-2017 23:50:09|Cras non velit ne...|          928|Nullam sit amet t...|Assigned|\n             4|       Swift-Goldner|27-01-2017 00:32:52|Vestibulum ac est...|           73|In hac habitasse ...|  Closed|\n             5|Crist, Armstrong ...|25-05-2017 21:57:27|Duis aliquam conv...|          978|Curabitur gravida...|  Closed|\n+--------------+--------------------+-------------------+--------------------+-------------+--------------------+--------+\nonly showing top 5 rows\n\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3673d3a9-cda1-481d-9c3a-ae575e0f47de"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"project_with_partition FINAL file","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4321669744917212}},"nbformat":4,"nbformat_minor":0}
