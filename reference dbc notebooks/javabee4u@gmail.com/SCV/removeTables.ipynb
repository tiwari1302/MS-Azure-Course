{"cells":[{"cell_type":"code","source":["%sql  show tables"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"875b1c4c-ddfb-4585-a35e-a4a220abd240"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["default","c1_email_data",false],["default","c1_email_output",false],["default","c1_firstname_dob_city_data",false],["default","c1_firstname_ip_data",false],["default","c1_firstname_ip_output",false],["default","c1_firstname_lastname_addr1_data",false],["default","c1_firstname_postcode_data",false],["default","c1_firstname_username_data",false],["default","c1_firstname_username_output",false],["default","c1_fn_mobile_data",false],["default","c1_postcode_addr1_data",false],["default","c1_postcode_dob_data",false],["default","emailview_output",false],["default","users_load",false],["default","userscv",false]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"database","type":"\"string\"","metadata":"{}"},{"name":"tableName","type":"\"string\"","metadata":"{}"},{"name":"isTemporary","type":"\"boolean\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>tableName</th><th>isTemporary</th></tr></thead><tbody><tr><td>default</td><td>c1_email_data</td><td>false</td></tr><tr><td>default</td><td>c1_email_output</td><td>false</td></tr><tr><td>default</td><td>c1_firstname_dob_city_data</td><td>false</td></tr><tr><td>default</td><td>c1_firstname_ip_data</td><td>false</td></tr><tr><td>default</td><td>c1_firstname_ip_output</td><td>false</td></tr><tr><td>default</td><td>c1_firstname_lastname_addr1_data</td><td>false</td></tr><tr><td>default</td><td>c1_firstname_postcode_data</td><td>false</td></tr><tr><td>default</td><td>c1_firstname_username_data</td><td>false</td></tr><tr><td>default</td><td>c1_firstname_username_output</td><td>false</td></tr><tr><td>default</td><td>c1_fn_mobile_data</td><td>false</td></tr><tr><td>default</td><td>c1_postcode_addr1_data</td><td>false</td></tr><tr><td>default</td><td>c1_postcode_dob_data</td><td>false</td></tr><tr><td>default</td><td>emailview_output</td><td>false</td></tr><tr><td>default</td><td>users_load</td><td>false</td></tr><tr><td>default</td><td>userscv</td><td>false</td></tr></tbody></table></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["%sql DROP TABLE if exists apartment\n%sql DROP TABLE apartment_data\n%sql DROP TABLE apartment_i\n%sql DROP TABLE apartment_maintenance\n%sql DROP TABLE apartment_maintenance_i\n%sql DROP TABLE building\n%sql DROP TABLE building_data\n%sql DROP TABLE building_i\n%sql DROP TABLE contractor\n%sql DROP TABLE contractor_data\n%sql DROP TABLE contractor_i\n%sql DROP TABLE d_affl\n%sql DROP TABLE d_frontend\n%sql DROP TABLE dailyplayer\n%sql DROP TABLE f_player\n%sql DROP TABLE foo_csv\n%sql DROP TABLE landlord\n%sql DROP TABLE landlord_data\n%sql DROP TABLE landlord_i\n%sql DROP TABLE landlord_new\n%sql DROP TABLE new_sample\n%sql DROP TABLE newdata\n%sql DROP TABLE olddata\n%sql DROP TABLE report\n%sql DROP TABLE temp_landlord_data\n%sql DROP TABLE tenant\n%sql DROP TABLE tenant_data\n%sql DROP TABLE tenant_i\n%sql DROP TABLE test_csv\n%sql DROP TABLE user_sample_2_1f270_csv\n%sql DROP TABLE user_sample_2_csv\n%sql DROP TABLE user_trans_csv\n%sql DROP TABLE userdata\n%sql DROP TABLE users_load\n%sql DROP TABLE userscv\n%sql DROP TABLE usertransactiontype\n%sql DROP TABLE usertransactiontype_csv\n%sql DROP TABLE usertransactiontypelatest\n%sql DROP TABLE usertransactiontypelatest_csv\n%sql DROP TABLE usertransdata"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e151feb-fcd2-4a37-b07c-346d7ac73e1d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"com.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.catalyst.parser.ParseException: \nmismatched input '%' expecting {'(', 'SELECT', 'FROM', 'ADD', 'DESC', 'WITH', 'VALUES', 'CREATE', 'TABLE', 'INSERT', 'DELETE', 'DESCRIBE', 'EXPLAIN', 'SHOW', 'USE', 'DROP', 'ALTER', 'MAP', 'SET', 'RESET', 'START', 'COMMIT', 'ROLLBACK', 'MERGE', 'UPDATE', 'REDUCE', 'REFRESH', 'CLEAR', 'CACHE', 'UNCACHE', 'DFS', 'TRUNCATE', 'ANALYZE', 'LIST', 'REVOKE', 'GRANT', 'LOCK', 'UNLOCK', 'MSCK', 'EXPORT', 'IMPORT', 'LOAD', 'OPTIMIZE'}(line 1, pos 0)\n\n== SQL ==\n%sql DROP TABLE apartment_data\n^^^\n\n\tat org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:239)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:115)\n\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:51)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(ParseDriver.scala:69)\n\tat com.databricks.sql.parser.DatabricksSqlParser$$anonfun$parsePlan$1.apply(DatabricksSqlParser.scala:53)\n\tat com.databricks.sql.parser.DatabricksSqlParser$$anonfun$parsePlan$1.apply(DatabricksSqlParser.scala:50)\n\tat com.databricks.sql.parser.DatabricksSqlParser.parse(DatabricksSqlParser.scala:72)\n\tat com.databricks.sql.parser.DatabricksSqlParser.parsePlan(DatabricksSqlParser.scala:50)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:639)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:707)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal$$anonfun$1.apply(SQLDriverLocal.scala:87)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal$$anonfun$1.apply(SQLDriverLocal.scala:33)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:285)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:33)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:136)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:249)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:229)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:43)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:43)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:229)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:596)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:554)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:122)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:136)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:249)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:229)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:43)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:43)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:229)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:596)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:554)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorSummary":"Error in SQL statement: ParseException: \nmismatched input '%' expecting {'(', 'SELECT', 'FROM', 'ADD', 'DESC', 'WITH', 'VALUES', 'CREATE', 'TABLE', 'INSERT', 'DELETE', 'DESCRIBE', 'EXPLAIN', 'SHOW', 'USE', 'DROP', 'ALTER', 'MAP', 'SET', 'RESET', 'START', 'COMMIT', 'ROLLBACK', 'MERGE', 'UPDATE', 'REDUCE', 'REFRESH', 'CLEAR', 'CACHE', 'UNCACHE', 'DFS', 'TRUNCATE', 'ANALYZE', 'LIST', 'REVOKE', 'GRANT', 'LOCK', 'UNLOCK', 'MSCK', 'EXPORT', 'IMPORT', 'LOAD', 'OPTIMIZE'}(line 1, pos 0)\n\n== SQL ==\n%sql DROP TABLE apartment_data\n^^^\n","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\ncom.databricks.backend.common.rpc.DatabricksExceptions$SQLExecutionException: org.apache.spark.sql.catalyst.parser.ParseException: \nmismatched input '%' expecting {'(', 'SELECT', 'FROM', 'ADD', 'DESC', 'WITH', 'VALUES', 'CREATE', 'TABLE', 'INSERT', 'DELETE', 'DESCRIBE', 'EXPLAIN', 'SHOW', 'USE', 'DROP', 'ALTER', 'MAP', 'SET', 'RESET', 'START', 'COMMIT', 'ROLLBACK', 'MERGE', 'UPDATE', 'REDUCE', 'REFRESH', 'CLEAR', 'CACHE', 'UNCACHE', 'DFS', 'TRUNCATE', 'ANALYZE', 'LIST', 'REVOKE', 'GRANT', 'LOCK', 'UNLOCK', 'MSCK', 'EXPORT', 'IMPORT', 'LOAD', 'OPTIMIZE'}(line 1, pos 0)\n\n== SQL ==\n%sql DROP TABLE apartment_data\n^^^\n\n\tat org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:239)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:115)\n\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:51)\n\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(ParseDriver.scala:69)\n\tat com.databricks.sql.parser.DatabricksSqlParser$$anonfun$parsePlan$1.apply(DatabricksSqlParser.scala:53)\n\tat com.databricks.sql.parser.DatabricksSqlParser$$anonfun$parsePlan$1.apply(DatabricksSqlParser.scala:50)\n\tat com.databricks.sql.parser.DatabricksSqlParser.parse(DatabricksSqlParser.scala:72)\n\tat com.databricks.sql.parser.DatabricksSqlParser.parsePlan(DatabricksSqlParser.scala:50)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:639)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:707)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal$$anonfun$1.apply(SQLDriverLocal.scala:87)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal$$anonfun$1.apply(SQLDriverLocal.scala:33)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:285)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:33)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:136)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:249)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:229)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:43)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:43)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:229)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:596)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:554)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.executeSql(SQLDriverLocal.scala:122)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:136)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:249)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$3.apply(DriverLocal.scala:229)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:188)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:183)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:43)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:221)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:43)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:229)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:601)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:596)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.getCommandOutputAndError(DriverWrapper.scala:486)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:554)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:748)"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["spark.sql('DROP TABLE IF EXISTS c1_firstname_postcode_data')\nspark.sql('DROP TABLE IF EXISTS c1_firstname_username_data')\nspark.sql('DROP TABLE IF EXISTS c1_firstname_username_output')\nspark.sql('DROP TABLE IF EXISTS c1_fn_mobile_data')\nspark.sql('DROP TABLE IF EXISTS c1_postcode_addr1_data')\nspark.sql('DROP TABLE IF EXISTS c1_postcode_dob_data')\nspark.sql('DROP TABLE IF EXISTS c1_email_data')\nspark.sql('DROP TABLE IF EXISTS c1_email_output')\nspark.sql('DROP TABLE IF EXISTS c1_firstname_dob_city_data')\nspark.sql('DROP TABLE IF EXISTS c1_firstname_ip_data')\nspark.sql('DROP TABLE IF EXISTS c1_firstname_ip_output')\nspark.sql('DROP TABLE IF EXISTS c1_firstname_lastname_addr1_data')\nspark.sql('DROP TABLE IF EXISTS users_load')\nspark.sql('DROP TABLE IF EXISTS userscv')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"450d7478-982e-4948-be95-929b8189ea02"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">2</span><span class=\"ansired\">]: </span>DataFrame[]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">2</span><span class=\"ansired\">]: </span>DataFrame[]\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["spark.sql('DROP TABLE IF EXISTS apartment')\nspark.sql('DROP TABLE IF EXISTS apartment_data')\nspark.sql('DROP TABLE IF EXISTS apartment_i')\nspark.sql('DROP TABLE IF EXISTS apartment_maintenance')\nspark.sql('DROP TABLE IF EXISTS apartment_maintenance_i')\nspark.sql('DROP TABLE IF EXISTS building')\nspark.sql('DROP TABLE IF EXISTS building_data')\nspark.sql('DROP TABLE IF EXISTS building_i')\nspark.sql('DROP TABLE IF EXISTS contractor')\nspark.sql('DROP TABLE IF EXISTS contractor_data')\nspark.sql('DROP TABLE IF EXISTS contractor_i')\nspark.sql('DROP TABLE IF EXISTS d_affl')\nspark.sql('DROP TABLE IF EXISTS d_frontend')\nspark.sql('DROP TABLE IF EXISTS dailyplayer')\nspark.sql('DROP TABLE IF EXISTS f_player')\nspark.sql('DROP TABLE IF EXISTS foo_csv')\nspark.sql('DROP TABLE IF EXISTS landlord')\nspark.sql('DROP TABLE IF EXISTS landlord_data')\nspark.sql('DROP TABLE IF EXISTS landlord_i')\nspark.sql('DROP TABLE IF EXISTS landlord_new')\nspark.sql('DROP TABLE IF EXISTS new_sample')\nspark.sql('DROP TABLE IF EXISTS newdata')\nspark.sql('DROP TABLE IF EXISTS olddata')\nspark.sql('DROP TABLE IF EXISTS report')\nspark.sql('DROP TABLE IF EXISTS temp_landlord_data')\nspark.sql('DROP TABLE IF EXISTS tenant')\nspark.sql('DROP TABLE IF EXISTS tenant_data')\nspark.sql('DROP TABLE IF EXISTS tenant_i')\nspark.sql('DROP TABLE IF EXISTS test_csv')\nspark.sql('DROP TABLE IF EXISTS user_sample_2_1f270_csv')\nspark.sql('DROP TABLE IF EXISTS user_sample_2_csv')\nspark.sql('DROP TABLE IF EXISTS user_trans_csv')\nspark.sql('DROP TABLE IF EXISTS userdata')\nspark.sql('DROP TABLE IF EXISTS users_load')\nspark.sql('DROP TABLE IF EXISTS userscv')\nspark.sql('DROP TABLE IF EXISTS usertransactiontype')\nspark.sql('DROP TABLE IF EXISTS usertransactiontype_csv')\nspark.sql('DROP TABLE IF EXISTS usertransactiontypelatest')\nspark.sql('DROP TABLE IF EXISTS usertransactiontypelatest_csv')\nspark.sql('DROP TABLE IF EXISTS usertransdata')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"76729179-67a9-4cfb-b257-249565d4e068"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">2</span><span class=\"ansired\">]: </span>DataFrame[]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">2</span><span class=\"ansired\">]: </span>DataFrame[]\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["## I did this \n# Is there no way to programmtically get list an ddrop these tables?\n\n# show tables ???\nspark.sql('DROP TABLE IF EXISTS apartment_data ')  \nspark.sql('DROP TABLE IF EXISTS apartment_i ')  \nspark.sql('DROP TABLE IF EXISTS apartment_maintenance ')  \nspark.sql('DROP TABLE IF EXISTS building ')  \nspark.sql('DROP TABLE IF EXISTS building_data ')  \nspark.sql('DROP TABLE IF EXISTS building_i ')  \nspark.sql('DROP TABLE IF EXISTS contractor ')  \nspark.sql('DROP TABLE IF EXISTS contractor_data ')  \nspark.sql('DROP TABLE IF EXISTS contractor_i ')  \nspark.sql('DROP TABLE IF EXISTS d_affl ')  \nspark.sql('DROP TABLE IF EXISTS d_frontend ')  \nspark.sql('DROP TABLE IF EXISTS dailyplayer ')  \nspark.sql('DROP TABLE IF EXISTS f_player ')  \nspark.sql('DROP TABLE IF EXISTS foo_csv ')  \nspark.sql('DROP TABLE IF EXISTS landlord ')  \nspark.sql('DROP TABLE IF EXISTS Iandlord_data ')  \nspark.sql('DROP TABLE IF EXISTS Iandlord_i ')  \nspark.sql('DROP TABLE IF EXISTS Iandlord_new ')  \nspark.sql('DROP TABLE IF EXISTS new_sample ')  \nspark.sql('DROP TABLE IF EXISTS newdata ')  \nspark.sql('DROP TABLE IF EXISTS olddata ')  \nspark.sql('DROP TABLE IF EXISTS report ')  \nspark.sql('DROP TABLE IF EXISTS temp_landlord_data ')  \nspark.sql('DROP TABLE IF EXISTS tenant ')  \nspark.sql('DROP TABLE IF EXISTS tenant_data ')  \nspark.sql('DROP TABLE IF EXISTS tenant_i ')  \nspark.sql('DROP TABLE IF EXISTS test_csv ')  \nspark.sql('DROP TABLE IF EXISTS apartment_maintenance ')  \nspark.sql('DROP TABLE IF EXISTS landlord_data ')  \nspark.sql('DROP TABLE IF EXISTS landlord_i ')  \nspark.sql('DROP TABLE IF EXISTS landlord_new ')  \nspark.sql('DROP TABLE IF EXISTS  user_sample_2_1f2 ')  \nspark.sql('DROP TABLE IF EXISTS user_sample_2_csv ')  \nspark.sql('DROP TABLE IF EXISTS user_trans_csv ')  \nspark.sql('DROP TABLE IF EXISTS userdata ')  \nspark.sql('DROP TABLE IF EXISTS users_load ')  \nspark.sql('DROP TABLE IF EXISTS userscv ')  \nspark.sql('DROP TABLE IF EXISTS  usertransactiontype ')  \nspark.sql('DROP TABLE IF EXISTS usertransactiontype ')  \nspark.sql('DROP TABLE IF EXISTS usertransactiontypel ')  \nspark.sql('DROP TABLE IF EXISTS usertransactiontypel ')  \nspark.sql('DROP TABLE IF EXISTS usertransdata ')  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"56d6eaf4-b86c-44b2-8dc0-246a1d030089"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"removeTables","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4321669744918120}},"nbformat":4,"nbformat_minor":0}
