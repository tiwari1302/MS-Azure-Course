{"cells":[{"cell_type":"markdown","source":["d-sandbox\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 400px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2820255b-83f4-488b-8c88-42da61ef304e"}}},{"cell_type":"markdown","source":["# User-Defined Functions\n\n##### Methods\n- UDF Registration (`spark.udf`) (<a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=udfregistration#pyspark.sql.UDFRegistration\" target=\"_blank\">Python</a>/<a href=\"http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/UDFRegistration.html\" target=\"_blank\">Scala</a>): `register`\n- Built-In Functions (<a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=functions#module-pyspark.sql.functions\" target=\"_blank\">Python</a>/<a href=\"http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/functions$.html\" target=\"_blank\">Scala</a>): `udf`\n- Python UDF Decorator (<a href=\"https://docs.databricks.com/spark/latest/spark-sql/udf-python.html#use-udf-with-dataframes\" target=\"_blank\">Databricks</a>): `@udf`\n- Pandas UDF Decorator (<a href=\"https://docs.databricks.com/spark/latest/spark-sql/udf-python-pandas.html#pandas-user-defined-functions\" target=\"_blank\">Databricks</a>): `@pandas_udf`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"748c5c7d-49cd-418e-8154-8b503bd8d282"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5fd0691d-d3ea-4c10-9156-9286524ccde8"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["salesDF = spark.read.parquet(salesPath)\ndisplay(salesDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"809f563e-85ec-422d-9c51-6b4ea80eb476"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Define a function\n\nDefine a function in local Python/Scala to get the first letter of a string from the `email` field."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd950219-0092-4b1a-8192-0310cf20e78c"}}},{"cell_type":"code","source":["def firstLetterFunction(email):\n  return email[0]\n\nfirstLetterFunction(\"annagray@kaufman.com\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad3e68ee-8226-4dd1-97a3-cc3bed18b94e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Create and apply UDF\nDefine a UDF that wraps the function. This serializes the function and sends it to executors to be able to use in our DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de1d5de8-3435-4454-bb83-e8c0e8025059"}}},{"cell_type":"code","source":["firstLetterUDF = udf(firstLetterFunction)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49c4a153-dacb-4340-bbca-d5d267647d76"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Apply UDF on the `email` column."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06737b14-1904-4f86-a4d1-caeb7fb8f565"}}},{"cell_type":"code","source":["from pyspark.sql.functions import col\ndisplay(salesDF.select(firstLetterUDF(col(\"email\"))))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca88736e-7b52-4f79-9eaf-b0c2bc8a11f8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Register UDF to use in SQL\nRegister UDF using `spark.udf.register` to create UDF in the SQL namespace."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a5337c0-45a0-416b-a7d9-ebc6f836e0a2"}}},{"cell_type":"code","source":["salesDF.createOrReplaceTempView(\"sales\")\n\nspark.udf.register(\"sql_udf\", firstLetterFunction)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c154e36d-5f03-45dd-a6e6-2b7025160dd6"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\nSELECT sql_udf(email) AS firstLetter FROM sales"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"33aa50e8-c283-4ba1-abf8-5aa053b3afe9"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Decorator Syntax (Python Only)\n\nAlternatively, define UDF using decorator syntax in Python with the datatype the function returns. \n\nYou will no longer be able to call the local Python function (e.g. `decoratorUDF(\"annagray@kaufman.com\")` will not work)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ee19aab1-a21c-4276-ad28-3f2458955801"}}},{"cell_type":"code","source":["%python\n# Our input/output is a string\n@udf(\"string\")\ndef decoratorUDF(email: str) -> str:\n  return email[0]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca2b3454-7e60-4c50-9411-3f31c3e165c5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\nfrom pyspark.sql.functions import col\nsalesDF = spark.read.parquet(\"/mnt/training/ecommerce/sales/sales.parquet\")\ndisplay(salesDF.select(decoratorUDF(col(\"email\"))))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82a778cb-d3f1-465b-a556-3419bd9f812f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Vectorized UDF (Python Only)\n\nUse Vectorized UDF to help speed up the computation using Apache Arrow."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be3fde40-d99a-485d-960a-c0123d84fdd4"}}},{"cell_type":"code","source":["%python\nimport pandas as pd\nfrom pyspark.sql.functions import pandas_udf\n\n# We have a string input/output\n@pandas_udf(\"string\")\ndef vectorizedUDF(email: pd.Series) -> pd.Series:\n  return email.str[0]\n\n# Alternatively\nvectorizedUDF = pandas_udf(lambda s: s.str[0], \"string\")  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db4de9b0-64ee-453a-bfdc-49aba9f0500e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%python\ndisplay(salesDF.select(vectorizedUDF(col(\"email\"))))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"58899d84-f6c9-4d54-8c63-9e217fc7b849"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We can also register these Vectorized UDFs to the SQL namespace."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0fdf4cb9-cb2b-42ab-920f-dfca6d1ee242"}}},{"cell_type":"code","source":["%python\nspark.udf.register(\"sql_vectorized_udf\", vectorizedUDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a505180d-c651-40d2-a7c2-066e6ae8a4d6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Sort Day Lab"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9510fa7e-786a-45c7-b162-b151c4587c81"}}},{"cell_type":"markdown","source":["Start with a DataFrame of the average number of active users by day of week.\n\nThis was the resulting `df` in a previous lab."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bb13c26f-9102-436f-8bc2-b81c91fcd8cf"}}},{"cell_type":"code","source":["from pyspark.sql.functions import approx_count_distinct, avg, col, date_format, to_date\n\ndf = (spark.read.parquet(eventsPath)\n  .withColumn(\"ts\", (col(\"event_timestamp\") / 1e6).cast(\"timestamp\"))\n  .withColumn(\"date\", to_date(\"ts\"))\n  .groupBy(\"date\").agg(approx_count_distinct(\"user_id\").alias(\"active_users\"))\n  .withColumn(\"day\", date_format(col(\"date\"), \"E\"))\n  .groupBy(\"day\").agg(avg(col(\"active_users\")).alias(\"avg_users\")))\n\ndisplay(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f0b6337-4e38-4d0c-98ed-732afaa82be0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 1. Define UDF to label day of week\n- Use the **`labelDayOfWeek`** provided below to create the udf **`labelDowUDF`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ddfbecd-12b8-4841-9713-f47f8dc7be23"}}},{"cell_type":"code","source":["def labelDayOfWeek(day):\n  dow = {\"Mon\": \"1\", \"Tue\": \"2\", \"Wed\": \"3\", \"Thu\": \"4\",\n         \"Fri\": \"5\", \"Sat\": \"6\", \"Sun\": \"7\"}\n  return dow.get(day) + \"-\" + day"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc9102a5-b4e4-4446-afa6-4976f3d4f28d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 2. Apply UDF to label and sort by by weekday\n- Update the **`day`** column by applying the UDF and replacing this column\n- Sort by **`day`**\n- Plot as bar graph"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c78eb872-be8f-4415-9248-038284a76126"}}},{"cell_type":"code","source":["# TODO\nfinalDF = FILL_IN\n\ndisplay(finalDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2867fd88-c1cc-4db8-ad5e-e2a382cb2cd4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Clean up classroom"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7d98027-8442-4344-b25f-adffc3877a51"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Cleanup\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e29a17db-c73b-4b29-867d-bf202edae11f"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"2.5 UDFs","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4321669744914397}},"nbformat":4,"nbformat_minor":0}
