{"cells":[{"cell_type":"code","source":["\n#############################################\n# TAG API FUNCTIONS\n#############################################\n\n# Get all tags\ndef getTags() -> dict: \n  return sc._jvm.scala.collection.JavaConversions.mapAsJavaMap(\n    dbutils.entry_point.getDbutils().notebook().getContext().tags()\n  )\n\n# Get a single tag's value\ndef getTag(tagName: str, defaultValue: str = None) -> str:\n  values = getTags()[tagName]\n  try:\n    if len(values) > 0:\n      return values\n  except:\n    return defaultValue\n\n#############################################\n# USER, USERNAME, AND USERHOME FUNCTIONS\n#############################################\n\n# Get the user's username\ndef getUsername() -> str:\n  import uuid\n  try:\n    return dbutils.widgets.get(\"databricksUsername\")\n  except:\n    return getTag(\"user\", str(uuid.uuid1()).replace(\"-\", \"\"))\n\n# Get the user's userhome\ndef getUserhome() -> str:\n  username = getUsername()\n  return \"dbfs:/user/{}\".format(username)\n\ndef getModuleName() -> str: \n  # This will/should fail if module-name is not defined in the Classroom-Setup notebook\n  return spark.conf.get(\"com.databricks.training.module-name\")\n\ndef getLessonName() -> str:\n  # If not specified, use the notebook's name.\n  return dbutils.entry_point.getDbutils().notebook().getContext().notebookPath().getOrElse(None).split(\"/\")[-1]\n\ndef getWorkingDir() -> str:\n  import re\n  langType = \"p\" # for python\n  moduleName = re.sub(r\"[^a-zA-Z0-9]\", \"_\", getModuleName()).lower()\n  workingDir = \"{}/{}/{}\".format(getUserhome(), moduleName, langType)\n  return workingDir.replace(\"__\", \"_\").replace(\"__\", \"_\").replace(\"__\", \"_\").replace(\"__\", \"_\")\n    \n############################################\n# USER DATABASE FUNCTIONS\n############################################\n\ndef getDatabaseName(username:str, moduleName:str) -> str:\n  import re\n  user = re.sub(\"[^a-zA-Z0-9]\", \"\", username)\n  module = re.sub(\"[^a-zA-Z0-9]\", \"_\", moduleName)  \n  langType = \"py\" # for python\n  databaseName = (module + \"_\" + user + \"_\" + langType).lower()\n  return databaseName\n\n\n# Create a user-specific database\ndef createUserDatabase(username:str, moduleName:str) -> str:\n  databaseName = getDatabaseName(username, moduleName)\n\n  spark.sql(\"CREATE DATABASE IF NOT EXISTS {}\".format(databaseName))\n  spark.sql(\"USE {}\".format(databaseName))\n\n  return databaseName\n\n# ****************************************************************************\n# Utility method to determine whether a path exists\n# ****************************************************************************\n\ndef pathExists(path):\n  try:\n    dbutils.fs.ls(path)\n    return True\n  except:\n    return False\n  \n# ****************************************************************************\n# Utility method for recursive deletes\n# Note: dbutils.fs.rm() does not appear to be truely recursive\n# ****************************************************************************\n\ndef deletePath(path):\n  files = dbutils.fs.ls(path)\n\n  for file in files:\n    deleted = dbutils.fs.rm(file.path, True)\n    \n    if deleted == False:\n      if file.is_dir:\n        deletePath(file.path)\n      else:\n        raise IOError(\"Unable to delete file: \" + file.path)\n  \n  if dbutils.fs.rm(path, True) == False:\n    raise IOError(\"Unable to delete directory: \" + path)\n\n# ****************************************************************************\n# Utility method to clean up the workspace at the end of a lesson\n# ****************************************************************************\n\ndef classroomCleanup(username:str, moduleName:str, dropDatabase:str): \n  import time\n  \n  # Stop any active streams\n  for stream in spark.streams.active:\n    stream.stop()\n    \n    # Wait for the stream to stop\n    queries = list(filter(lambda query: query.name == stream.name, spark.streams.active))\n    \n    while (len(queries) > 0):\n      time.sleep(5) # Give it a couple of seconds\n      queries = list(filter(lambda query: query.name == stream.name, spark.streams.active))\n  \n  # Drop all tables from the specified database\n  database = getDatabaseName(username, moduleName)\n  try:\n    tables = spark.sql(\"show tables from {}\".format(database)).select(\"tableName\").collect()\n    for row in tables:\n      tableName = row[\"tableName\"]\n      spark.sql(\"drop table if exists {}.{}\".format(database, tableName))\n\n      # In some rare cases the files don't actually get removed.\n      time.sleep(1) # Give it just a second...\n      hivePath = \"dbfs:/user/hive/warehouse/{}.db/{}\".format(database, tableName)\n      dbutils.fs.rm(hivePath, True) # Ignoring the delete's success or failure\n    \n\n  except:\n    pass # ignored\n\n  # Remove any files that may have been created from previous runs\n  path = getWorkingDir()\n  if pathExists(path):\n    deletePath(path)  \n  \n  # The database should only be dropped in a \"cleanup\" notebook, not \"setup\"\n  if dropDatabase: \n    spark.sql(\"DROP DATABASE IF EXISTS {} CASCADE\".format(database))\n    \n    # In some rare cases the files don't actually get removed.\n    time.sleep(1) # Give it just a second...\n    hivePath = \"dbfs:/user/hive/warehouse/{}.db\".format(database)\n    dbutils.fs.rm(hivePath, True) # Ignoring the delete's success or failure\n    \n    displayHTML(\"Dropped database and removed files in working directory\")\n\n  \n# Utility method to delete a database  \ndef deleteTables(database):\n  spark.sql(\"DROP DATABASE IF EXISTS {} CASCADE\".format(database))\n  \n# ****************************************************************************\n# Placeholder variables for coding challenge type specification\n# ****************************************************************************\nclass FILL_IN:\n  from pyspark.sql.types import Row, StructType\n  VALUE = None\n  LIST = []\n  SCHEMA = StructType([])\n  ROW = Row()\n  INT = 0\n  DATAFRAME = sqlContext.createDataFrame(sc.emptyRDD(), StructType([]))\n\n############################################\n# Set up student environment\n############################################\n\nmoduleName = getModuleName()\nusername = getUsername()\nuserhome = getUserhome()\nworkingDir = getWorkingDir()\ndatabaseName = createUserDatabase(username, moduleName)\n\nclassroomCleanup(username, moduleName, False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"58cfecaa-5ea9-473d-a183-369ec219e40d"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Student-Environment","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4321669744914487}},"nbformat":4,"nbformat_minor":0}
